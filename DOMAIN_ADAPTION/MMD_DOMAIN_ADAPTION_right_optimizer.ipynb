{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1078773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import Dataloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1024\n",
    "overlap_size = 0\n",
    "vel_cut_off_value = 0\n",
    "#features_of_interest = ['S:x_bottom', 'S:y_bottom', 'S:z_bottom', 'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top', 'S:Nominal_rotational_speed[rad/s]', 'S:Actual_rotational_speed[µm/s]', 'S:Actual_position_of_the_position_encoder(dy/dt)[µm/s]', 'S:Actual_position_of_the_motor_encoder(dy/dt)[µm/s]']\n",
    "features_of_interest = [\n",
    "    'S:x_bottom', 'S:y_bottom', 'S:z_bottom',\n",
    "    'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top'\n",
    "                        ]\n",
    "\n",
    "list_of_source_BSD_states = [\"1\", \"2\", \"3\", \"4\", \"10\", \"11\", \"12\", \"13\", \"19\", \"20\", \"21\", \"22\"]\n",
    "list_of_target_BSD_states = [\"5\", \"6\", \"7\", \"9\", \"14\", \"15\", \"16\", \"18\", \"23\", \"24\", \"25\", \"27\"]\n",
    "data_path = Path(os.getcwd()).parents[1]\n",
    "data_path = os.path.join(data_path, \"data\")\n",
    "dataloader_split = 0.9\n",
    "batch_size = 32\n",
    "\n",
    "source_loader = Dataloader.create_dataloader(data_path, list_of_source_BSD_states, window_size, overlap_size, features_of_interest, \"train\", dataloader_split, batch_size)\n",
    "target_loader = Dataloader.create_dataloader(data_path, list_of_target_BSD_states, window_size, overlap_size, features_of_interest, \"test\", dataloader_split, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ba674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        formula [(W−K+2P)/S]+1.\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=100, stride=1)#input: 1000\n",
    "        self.conv2 = nn.Conv1d(64,32,kernel_size=10, stride = 1, padding=1)#input: [(1000-100+2*0)/1]+1 = 901\n",
    "        self.batch1 =nn.BatchNorm1d(32)#input: [(901-10+2*1)/1]+1 = 894\n",
    "        self.conv3 = nn.Conv1d(32,32,kernel_size=5, stride = 1, padding=1) #input:894\n",
    "        self.batch2 =nn.BatchNorm1d(32)#input: [(894-5+2*1)/1]+1 = 892\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.conv1(x)) #conv1\n",
    "        x = self.conv2(x) #conv2\n",
    "        x = F.selu(self.batch1(x)) #batch1\n",
    "        x = self.conv3(x) #conv3\n",
    "        x = F.selu(self.batch2(x)) #batch2\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2])) #flatten\n",
    "        #x = self.fc1(x) #linear1\n",
    "        output = x\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73b6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_fc_size, hidden_fc_size_1, hidden_fc_size_2, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_fc_size, hidden_fc_size_1)\n",
    "        self.fc2 = nn.Linear(hidden_fc_size_1, hidden_fc_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_fc_size_2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x_fc1)\n",
    "        x_fc3 = self.fc3(x_fc2)\n",
    "        output = x_fc1, x_fc2, x_fc3\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "input_fc_size = 32*892 #25*40 \n",
    "hidden_fc_size_1 = 100\n",
    "hidden_fc_size_2 = 3\n",
    "output_size = 2\n",
    "\n",
    "\n",
    "\n",
    "model_fc = Classifier(input_fc_size, hidden_fc_size_1, hidden_fc_size_2, output_size)\n",
    "\n",
    "model_cnn = CNN(input_size)\n",
    "\n",
    "\n",
    "print(model_cnn)\n",
    "\n",
    "print(model_fc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfca53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mmd_loss import MMD_loss\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, fix_sigma = None, kernel_mul = 2.0, kernel_num = 5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = fix_sigma\n",
    "        return\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma = None):\n",
    "        n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        \n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2) \n",
    "        bandwidth_list = self.fix_sigma\n",
    "        kernel_val = [torch.exp(-L2_distance / sigma) for sigma in self.fix_sigma]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.gaussian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        loss = torch.mean(XX + YY - XY -YX)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4992a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag_phase, GAMMA_inter_class, GAMMA_intra_class):\n",
    "        \n",
    "        #Feature extraction\n",
    "        outputs_cnn = model_cnn(data.float())\n",
    "        x_fc1, x_fc2, x_fc3 = model_fc(outputs_cnn)\n",
    "        \n",
    "        batch_size = len(labels_source)         \n",
    "        \n",
    "        #Classification\n",
    "        source_x_flatten = outputs_cnn[:batch_size, :]\n",
    "        target_x_flatten = outputs_cnn[batch_size:, :]\n",
    "        x_src = x_fc1[:batch_size, :]\n",
    "        x_tar = x_fc1[batch_size:, :]\n",
    "        source_out = x_fc2[:batch_size, :]\n",
    "        target_out = x_fc2[batch_size:, :]\n",
    "        source_pred = x_fc3[:batch_size, :]\n",
    "        target_pred = x_fc3[batch_size:, :]\n",
    "        \n",
    "        #CE loss\n",
    "        source_ce_loss = criterion(source_pred, labels_source)\n",
    "        target_ce_loss = criterion(target_pred, labels_target)\n",
    "\n",
    "        #collect information about labels, predictions to calculate accuracy\n",
    "        n_correct_source = 0\n",
    "        n_correct_target = 0\n",
    "        n_samples_source = 0\n",
    "        n_samples_target = 0\n",
    "        \n",
    "        # list of classified latent space features in flattend CNN\n",
    "        class_0_source_x_flatten = source_x_flatten[labels_source==0]\n",
    "        class_1_source_x_flatten = source_x_flatten[labels_source==1]\n",
    "        class_0_target_x_flatten = target_x_flatten[labels_target==0]\n",
    "        class_1_target_x_flatten = target_x_flatten[labels_target==1]\n",
    "        \n",
    "        # list of classified latent space features in FC1\n",
    "        class_0_source_out = source_out[labels_source==0]\n",
    "        class_1_source_out = source_out[labels_source==1]\n",
    "        class_0_target_out = target_out[labels_target==0]\n",
    "        class_1_target_out = target_out[labels_target==1]\n",
    "        \n",
    "        # list of classified latent space features in FC2\n",
    "        class_0_source_x = x_src[labels_source==0]\n",
    "        class_1_source_x = x_src[labels_source==1]\n",
    "        class_0_target_x = x_tar[labels_target==0]\n",
    "        class_1_target_x = x_tar[labels_target==1]\n",
    "        \n",
    "        source_correct_pred = torch.argmax(source_pred)\n",
    "        source_correct_pred = source_correct_pred[source_correct_pred==labels_source]\n",
    "        acc_total_source = 100 * len(source_correct_pred)/len(labels_source)\n",
    "        \n",
    "        target_correct_pred = torch.argmax(target_pred)\n",
    "        target_correct_pred = target_correct_pred[target_correct_pred==labels_target]\n",
    "        acc_total_target = 100 * len(target_correct_pred)/len(labels_target)\n",
    "        \n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        \n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_0 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_0_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_1 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_1_target_x_flatten[:min_1_flatten,:])\n",
    "\n",
    "        mmd_x_class_0_0 = MMD_loss.forward(class_0_source_x[:min_0_x,:],class_0_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_1 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_1_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_0 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_0_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_1 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_1_target_out[:min_1_out,:])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #mmd_loss_inter_class = mmd_x_class_0_0 + mmd_x_class_1_1 + mmd_out_class_0_0 + mmd_out_class_1_1\n",
    "        mmd_loss_inter_class = mmd_flatten_class_0_0 + mmd_flatten_class_1_1\n",
    "\n",
    "        #Intraclass MMD loss\n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_1 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_1_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_0 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_0_target_x_flatten[:min_1_flatten,:])\n",
    "        \n",
    "        mmd_x_class_0_1= MMD_loss.forward(class_0_source_x[:min_0_x,:], class_1_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_0 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_0_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_1 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_1_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_0 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_0_target_out[:min_1_out,:])\n",
    "        \n",
    "        #mmd_loss_intra_class = mmd_x_class_0_1 + mmd_x_class_1_0 + mmd_out_class_0_1 + mmd_out_class_1_0\n",
    "        mmd_loss_intra_class = mmd_flatten_class_0_1 + mmd_flatten_class_1_0\n",
    "        \n",
    "        #total mmd loss\n",
    "        mmd_loss = GAMMA_inter_class * mmd_loss_inter_class - GAMMA_intra_class * mmd_loss_intra_class\n",
    "        \n",
    "        if MMD_loss_flag_phase == True:\n",
    "            loss = source_ce_loss + mmd_loss\n",
    "        else:\n",
    "            loss = source_ce_loss\n",
    "        \n",
    "        return loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_out, class_1_source_out, class_0_target_out, class_1_target_out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "writer_graph = SummaryWriter('runs/Dataloader2/graph')\n",
    "writer_source_val = SummaryWriter('runs/Dataloader2/source_val')\n",
    "writer_source_mmd = SummaryWriter('runs/Dataloader2/source_mmd')\n",
    "writer_source_ce = SummaryWriter('runs/Dataloader2/source_ce')\n",
    "writer_target_val = SummaryWriter('runs/Dataloader2/target_val')\n",
    "writer_target_mmd = SummaryWriter('runs/Dataloader2/target_mmd')\n",
    "writer_target_ce = SummaryWriter('runs/Dataloader2/target_ce')\n",
    "\n",
    "writer_source = {}\n",
    "writer_source[\"val\"] = writer_source_val\n",
    "writer_source[\"mmd\"] = writer_source_mmd\n",
    "writer_source[\"ce\"] = writer_source_ce\n",
    "\n",
    "writer_target = {}\n",
    "writer_target[\"val\"] = writer_target_val\n",
    "writer_target[\"mmd\"] = writer_target_mmd\n",
    "writer_target[\"ce\"] = writer_target_ce\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1 #0.008\n",
    "GAMMA_inter_class = 10\n",
    "GAMMA_intra_class = 10\n",
    "SIGMA = torch.tensor([1,2,4,8,16],dtype=torch.float64)\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "MMD_loss = MMD_loss(fix_sigma = SIGMA)\n",
    "#optimizer1 = torch.optim.SGD(model_cnn.parameters(), lr=learning_rate)\n",
    "optimizer2= torch.optim.SGD(model_fc.parameters(), lr=1e-2)\n",
    "\n",
    "optimizer1 = torch.optim.SGD([\n",
    "{'params': model_cnn.parameters()},\n",
    "{'params': model_fc.parameters(), 'lr': 1e-4}\n",
    "], lr=1e-2, momentum=0.9)\n",
    "\n",
    "#training iterations\n",
    "phases = [\"val\", \"mmd\", \"ce\"]\n",
    "\n",
    "#mmd_loss_flag\n",
    "MMD_loss_flag = {}\n",
    "MMD_loss_flag[\"val\"] = True\n",
    "MMD_loss_flag[\"mmd\"] = True\n",
    "MMD_loss_flag[\"ce\"] = False\n",
    "\n",
    "\n",
    "#init train data for each batch\n",
    "loss_collected = 0\n",
    "source_ce_loss_collected = 0\n",
    "target_ce_loss_collected = 0\n",
    "mmd_loss_collected = 0\n",
    "acc_total_source_collected = 0\n",
    "acc_total_target_collected = 0\n",
    "\n",
    "#plot lists\n",
    "mmd_loss_list = {}\n",
    "mmd_loss_list['val']=[]\n",
    "mmd_loss_list['mmd']=[]\n",
    "mmd_loss_list['ce'] = []\n",
    "\n",
    "ce_loss_list_source = {}\n",
    "ce_loss_list_source['val']=[]\n",
    "ce_loss_list_source['mmd']=[]\n",
    "ce_loss_list_source['ce'] = []\n",
    "\n",
    "ce_loss_list_target = {}\n",
    "ce_loss_list_target['val']=[]\n",
    "ce_loss_list_target['mmd']=[]\n",
    "ce_loss_list_target['ce'] = []\n",
    "\n",
    "accuracy_list_source = {}\n",
    "accuracy_list_source['val']=[]\n",
    "accuracy_list_source['mmd']=[]\n",
    "accuracy_list_source['ce'] = []\n",
    "\n",
    "accuracy_list_target = {}\n",
    "accuracy_list_target['val']=[]\n",
    "accuracy_list_target['mmd']=[]\n",
    "accuracy_list_target['ce'] = []\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    #plot mmd\n",
    "    class_0_source_out_collect = torch.empty((0,3))\n",
    "    class_1_source_out_collect = torch.empty((0,3))\n",
    "    class_0_target_out_collect = torch.empty((0,3))\n",
    "    class_1_target_out_collect = torch.empty((0,3))\n",
    "\n",
    "    \n",
    "    for phase in phases:\n",
    "        iter_loader_source = iter(source_loader[phase])\n",
    "        iter_loader_target = iter(target_loader[phase])\n",
    "        for i in range(len(iter_loader_source)):\n",
    "            \n",
    "            ########Forward pass########\n",
    "            data_source, labels_source = iter_loader_source.next() #batch_size number of windows and labels from source domain\n",
    "            data_target, labels_target = iter_loader_target.next() #batch_size number of windows from target domain\n",
    "            data = torch.cat((data_source, data_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "            \n",
    "            \n",
    "            if phase == \"val\":\n",
    "                \n",
    "                #no training\n",
    "                model_cnn.train(False)\n",
    "                model_fc.train(False)\n",
    "                \n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    _, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_out, class_1_source_out, class_0_target_out, class_1_target_out = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                    \n",
    "                    # collect latent features for plot \n",
    "                    class_0_source_out_collect = torch.cat((class_0_source_out_collect, class_0_source_out), 0)\n",
    "                    class_1_source_out_collect = torch.cat((class_1_source_out_collect, class_1_source_out), 0)\n",
    "                    class_0_target_out_collect = torch.cat((class_0_target_out_collect, class_0_target_out), 0)\n",
    "                    class_1_target_out_collect = torch.cat((class_1_target_out_collect, class_1_target_out), 0)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            elif phase == \"mmd\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer1.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer1.step()\n",
    "                \n",
    "            elif phase == \"ce\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer2.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer2.step()\n",
    "            \n",
    "            # collect train data for each train phase\n",
    "            mmd_loss_collected += mmd_loss\n",
    "            source_ce_loss_collected += source_ce_loss\n",
    "            target_ce_loss_collected += target_ce_loss\n",
    "            acc_total_source_collected += acc_total_source\n",
    "            acc_total_target_collected += acc_total_target\n",
    "            \n",
    "            \n",
    "                \n",
    "        #plot\n",
    "        if phase == \"val\" and (epoch ==0 or epoch ==2 or epoch == 4 or epoch ==6):\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.gcf().set_size_inches((20, 20)) \n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "            m = [1,2,3,4]\n",
    "            data = [class_0_source_out_collect, class_1_source_out_collect, class_0_target_out_collect, class_1_target_out_collect]\n",
    "            for i in range(4):\n",
    "                ax.scatter(data[i][:,0], data[i][:,1], data[i][:,2], marker=m[i])\n",
    "            \n",
    "            plt.show()\n",
    "            fig.savefig(f\"no_mmd_epoch{epoch}\")            \n",
    "\n",
    "        \n",
    "        # Normalize collected train data for each train phase\n",
    "        running_mmd_loss = mmd_loss_collected / len(source_loader[phase])\n",
    "        \n",
    "        running_acc_source = acc_total_source_collected / len(source_loader[phase])\n",
    "        running_acc_target = acc_total_target_collected / len(target_loader[phase])\n",
    "        \n",
    "        running_source_ce_loss = source_ce_loss_collected / len(source_loader[phase])\n",
    "        running_target_ce_loss = target_ce_loss_collected / len(target_loader[phase])\n",
    "        \n",
    "        \n",
    "        #Add train data to plot list\n",
    "        accuracy_list_source[phase].append(running_acc_source)\n",
    "        accuracy_list_target[phase].append(running_acc_target)\n",
    "        \n",
    "        ce_loss_list_source[phase].append(running_source_ce_loss)\n",
    "        ce_loss_list_target[phase].append(running_target_ce_loss)\n",
    "        \n",
    "        mmd_loss_list[phase].append(running_mmd_loss)\n",
    "\n",
    "\n",
    "        #Add train data to tensorflow list\n",
    "        writer_source[phase].add_scalar(f'accuracy', running_acc_source, epoch)\n",
    "        writer_target[phase].add_scalar(f'accuracy', running_acc_target, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'ce_loss', running_source_ce_loss, epoch)\n",
    "        writer_target[phase].add_scalar(f'ce_loss', running_target_ce_loss, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'mmd_loss', running_mmd_loss, epoch)\n",
    "        \n",
    "\n",
    "        #reset train data for each batch\n",
    "        loss_collected = 0\n",
    "        source_ce_loss_collected = 0\n",
    "        target_ce_loss_collected = 0\n",
    "        mmd_loss_collected = 0\n",
    "        acc_total_source_collected = 0\n",
    "        acc_total_target_collected = 0\n",
    "            \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c6269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
