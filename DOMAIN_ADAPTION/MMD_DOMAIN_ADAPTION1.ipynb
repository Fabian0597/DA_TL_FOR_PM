{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3601c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import Dataloader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36c37ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabiankolb/Documents/Universit√§t/TUM_Master/Masterarbeit/CODE/DA_TL_FOR_PM/DOMAIN_ADAPTION/../Dataloader.py:36: UserWarning: Not all elements were covered\n",
      "  warnings.warn(\"Not all elements were covered\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/020_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (22, 13, 1024), Y_shape: (22,)\n",
      "2/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/021_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (44, 13, 1024), Y_shape: (44,)\n",
      "3/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/023_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (66, 13, 1024), Y_shape: (66,)\n",
      "4/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/022_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (88, 13, 1024), Y_shape: (88,)\n",
      "5/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/019_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (110, 13, 1024), Y_shape: (110,)\n",
      "6/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/016_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (132, 13, 1024), Y_shape: (132,)\n",
      "7/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/017_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (154, 13, 1024), Y_shape: (154,)\n",
      "8/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/018_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (176, 13, 1024), Y_shape: (176,)\n",
      "9/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/015_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (198, 13, 1024), Y_shape: (198,)\n",
      "10/120 folders downloaded\n",
      "downloaded folder: NR01_20200317_PGS_31_BSD_31/014_2020_03_18.csv\n",
      "Shape of collected datafram: X_shape: (220, 13, 1024), Y_shape: (220,)\n",
      "11/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/046_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (242, 13, 1024), Y_shape: (242,)\n",
      "12/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/037_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (264, 13, 1024), Y_shape: (264,)\n",
      "13/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/041_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (286, 13, 1024), Y_shape: (286,)\n",
      "14/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/038_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (308, 13, 1024), Y_shape: (308,)\n",
      "15/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/039_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (330, 13, 1024), Y_shape: (330,)\n",
      "16/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/040_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (352, 13, 1024), Y_shape: (352,)\n",
      "17/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/045_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (374, 13, 1024), Y_shape: (374,)\n",
      "18/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/042_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (396, 13, 1024), Y_shape: (396,)\n",
      "19/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/043_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (418, 13, 1024), Y_shape: (418,)\n",
      "20/120 folders downloaded\n",
      "downloaded folder: NR02_20200423_PGS_31_BSD_21/044_2020_04_23.csv\n",
      "Shape of collected datafram: X_shape: (440, 13, 1024), Y_shape: (440,)\n",
      "21/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/063_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (462, 13, 1024), Y_shape: (462,)\n",
      "22/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/064_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (484, 13, 1024), Y_shape: (484,)\n",
      "23/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/065_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (506, 13, 1024), Y_shape: (506,)\n",
      "24/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/062_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (528, 13, 1024), Y_shape: (528,)\n",
      "25/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/068_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (550, 13, 1024), Y_shape: (550,)\n",
      "26/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/060_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (572, 13, 1024), Y_shape: (572,)\n",
      "27/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/067_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (594, 13, 1024), Y_shape: (594,)\n",
      "28/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/066_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (616, 13, 1024), Y_shape: (616,)\n",
      "29/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/061_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (638, 13, 1024), Y_shape: (638,)\n",
      "30/120 folders downloaded\n",
      "downloaded folder: NR03_20200424_PGS_31_BSD_11/069_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (660, 13, 1024), Y_shape: (660,)\n",
      "31/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/089_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (682, 13, 1024), Y_shape: (682,)\n",
      "32/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/081_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (704, 13, 1024), Y_shape: (704,)\n",
      "33/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/086_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (726, 13, 1024), Y_shape: (726,)\n",
      "34/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/087_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (748, 13, 1024), Y_shape: (748,)\n",
      "35/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/080_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (770, 13, 1024), Y_shape: (770,)\n",
      "36/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/088_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (792, 13, 1024), Y_shape: (792,)\n",
      "37/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/082_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (814, 13, 1024), Y_shape: (814,)\n",
      "38/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/085_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (836, 13, 1024), Y_shape: (836,)\n",
      "39/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/084_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (858, 13, 1024), Y_shape: (858,)\n",
      "40/120 folders downloaded\n",
      "downloaded folder: NR04_20200424_PGS_31_BSD_P1/083_2020_04_24.csv\n",
      "Shape of collected datafram: X_shape: (880, 13, 1024), Y_shape: (880,)\n",
      "41/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/177_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (902, 13, 1024), Y_shape: (902,)\n",
      "42/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/180_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (924, 13, 1024), Y_shape: (924,)\n",
      "43/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/178_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (946, 13, 1024), Y_shape: (946,)\n",
      "44/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/179_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (968, 13, 1024), Y_shape: (968,)\n",
      "45/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/181_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (990, 13, 1024), Y_shape: (990,)\n",
      "46/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/176_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1012, 13, 1024), Y_shape: (1012,)\n",
      "47/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/174_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1034, 13, 1024), Y_shape: (1034,)\n",
      "48/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/173_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1056, 13, 1024), Y_shape: (1056,)\n",
      "49/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/172_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1078, 13, 1024), Y_shape: (1078,)\n",
      "50/120 folders downloaded\n",
      "downloaded folder: NR10_20200502_PGS_21_BSD_31/175_2020_05_02.csv\n",
      "Shape of collected datafram: X_shape: (1100, 13, 1024), Y_shape: (1100,)\n",
      "51/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/149_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1122, 13, 1024), Y_shape: (1122,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/154_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1144, 13, 1024), Y_shape: (1144,)\n",
      "53/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/153_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1166, 13, 1024), Y_shape: (1166,)\n",
      "54/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/152_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1188, 13, 1024), Y_shape: (1188,)\n",
      "55/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/155_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1210, 13, 1024), Y_shape: (1210,)\n",
      "56/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/157_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1232, 13, 1024), Y_shape: (1232,)\n",
      "57/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/150_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1254, 13, 1024), Y_shape: (1254,)\n",
      "58/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/158_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1276, 13, 1024), Y_shape: (1276,)\n",
      "59/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/151_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1298, 13, 1024), Y_shape: (1298,)\n",
      "60/120 folders downloaded\n",
      "downloaded folder: NR11_20200429_PGS_21_BSD_21/156_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1320, 13, 1024), Y_shape: (1320,)\n",
      "61/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/130_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1342, 13, 1024), Y_shape: (1342,)\n",
      "62/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/131_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1364, 13, 1024), Y_shape: (1364,)\n",
      "63/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/126_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1386, 13, 1024), Y_shape: (1386,)\n",
      "64/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/133_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1408, 13, 1024), Y_shape: (1408,)\n",
      "65/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/134_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1430, 13, 1024), Y_shape: (1430,)\n",
      "66/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/129_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1452, 13, 1024), Y_shape: (1452,)\n",
      "67/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/128_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1474, 13, 1024), Y_shape: (1474,)\n",
      "68/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/135_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1496, 13, 1024), Y_shape: (1496,)\n",
      "69/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/132_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1518, 13, 1024), Y_shape: (1518,)\n",
      "70/120 folders downloaded\n",
      "downloaded folder: NR12_20200429_PGS_21_BSD_11/127_2020_04_29.csv\n",
      "Shape of collected datafram: X_shape: (1540, 13, 1024), Y_shape: (1540,)\n",
      "71/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/106_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1562, 13, 1024), Y_shape: (1562,)\n",
      "72/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/109_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1584, 13, 1024), Y_shape: (1584,)\n",
      "73/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/108_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1606, 13, 1024), Y_shape: (1606,)\n",
      "74/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/107_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1628, 13, 1024), Y_shape: (1628,)\n",
      "75/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/112_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1650, 13, 1024), Y_shape: (1650,)\n",
      "76/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/105_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1672, 13, 1024), Y_shape: (1672,)\n",
      "77/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/110_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1694, 13, 1024), Y_shape: (1694,)\n",
      "78/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/103_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1716, 13, 1024), Y_shape: (1716,)\n",
      "79/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/111_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1738, 13, 1024), Y_shape: (1738,)\n",
      "80/120 folders downloaded\n",
      "downloaded folder: NR13_20200428_PGS_21_BSD_P1/104_2020_04_28.csv\n",
      "Shape of collected datafram: X_shape: (1760, 13, 1024), Y_shape: (1760,)\n",
      "81/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/195_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1782, 13, 1024), Y_shape: (1782,)\n",
      "82/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/198_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1804, 13, 1024), Y_shape: (1804,)\n",
      "83/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/197_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1826, 13, 1024), Y_shape: (1826,)\n",
      "84/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/196_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1848, 13, 1024), Y_shape: (1848,)\n",
      "85/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/199_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1870, 13, 1024), Y_shape: (1870,)\n",
      "86/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/204_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1892, 13, 1024), Y_shape: (1892,)\n",
      "87/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/203_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1914, 13, 1024), Y_shape: (1914,)\n",
      "88/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/202_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1936, 13, 1024), Y_shape: (1936,)\n",
      "89/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/200_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1958, 13, 1024), Y_shape: (1958,)\n",
      "90/120 folders downloaded\n",
      "downloaded folder: NR19_20200505_PGS_11_BSD_31/201_2020_05_05.csv\n",
      "Shape of collected datafram: X_shape: (1980, 13, 1024), Y_shape: (1980,)\n",
      "91/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/220_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2002, 13, 1024), Y_shape: (2002,)\n",
      "92/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/227_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2024, 13, 1024), Y_shape: (2024,)\n",
      "93/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/226_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2046, 13, 1024), Y_shape: (2046,)\n",
      "94/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/221_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2068, 13, 1024), Y_shape: (2068,)\n",
      "95/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/223_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2090, 13, 1024), Y_shape: (2090,)\n",
      "96/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/224_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2112, 13, 1024), Y_shape: (2112,)\n",
      "97/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/225_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2134, 13, 1024), Y_shape: (2134,)\n",
      "98/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/222_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2156, 13, 1024), Y_shape: (2156,)\n",
      "99/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/219_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2178, 13, 1024), Y_shape: (2178,)\n",
      "100/120 folders downloaded\n",
      "downloaded folder: NR20_20200507_PGS_11_BSD_21/218_2020_05_07.csv\n",
      "Shape of collected datafram: X_shape: (2200, 13, 1024), Y_shape: (2200,)\n",
      "101/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/241_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2222, 13, 1024), Y_shape: (2222,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/249_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2244, 13, 1024), Y_shape: (2244,)\n",
      "103/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/246_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2266, 13, 1024), Y_shape: (2266,)\n",
      "104/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/247_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2288, 13, 1024), Y_shape: (2288,)\n",
      "105/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/248_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2310, 13, 1024), Y_shape: (2310,)\n",
      "106/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/240_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2332, 13, 1024), Y_shape: (2332,)\n",
      "107/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/242_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2354, 13, 1024), Y_shape: (2354,)\n",
      "108/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/245_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2376, 13, 1024), Y_shape: (2376,)\n",
      "109/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/244_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2398, 13, 1024), Y_shape: (2398,)\n",
      "110/120 folders downloaded\n",
      "downloaded folder: NR21_20200508_PGS_11_BSD_11/243_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2420, 13, 1024), Y_shape: (2420,)\n",
      "111/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/265_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2442, 13, 1024), Y_shape: (2442,)\n",
      "112/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/270_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2464, 13, 1024), Y_shape: (2464,)\n",
      "113/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/271_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2486, 13, 1024), Y_shape: (2486,)\n",
      "114/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/264_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2508, 13, 1024), Y_shape: (2508,)\n",
      "115/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/263_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2530, 13, 1024), Y_shape: (2530,)\n",
      "116/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/269_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2552, 13, 1024), Y_shape: (2552,)\n",
      "117/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/266_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2574, 13, 1024), Y_shape: (2574,)\n",
      "118/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/267_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2596, 13, 1024), Y_shape: (2596,)\n",
      "119/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/272_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2618, 13, 1024), Y_shape: (2618,)\n",
      "120/120 folders downloaded\n",
      "downloaded folder: NR22_20200508_PGS_11_BSD_P1/268_2020_05_08.csv\n",
      "Shape of collected datafram: X_shape: (2640, 13, 1024), Y_shape: (2640,)\n",
      "1/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/478_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (22, 13, 1024), Y_shape: (22,)\n",
      "2/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/480_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (44, 13, 1024), Y_shape: (44,)\n",
      "3/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/477_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (66, 13, 1024), Y_shape: (66,)\n",
      "4/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/476_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (88, 13, 1024), Y_shape: (88,)\n",
      "5/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/481_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (110, 13, 1024), Y_shape: (110,)\n",
      "6/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/479_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (132, 13, 1024), Y_shape: (132,)\n",
      "7/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/484_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (154, 13, 1024), Y_shape: (154,)\n",
      "8/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/483_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (176, 13, 1024), Y_shape: (176,)\n",
      "9/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/482_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (198, 13, 1024), Y_shape: (198,)\n",
      "10/120 folders downloaded\n",
      "downloaded folder: NR05_20200930_PGS_31_BSD_22/475_2020_09_30.csv\n",
      "Shape of collected datafram: X_shape: (220, 13, 1024), Y_shape: (220,)\n",
      "11/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/503_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (242, 13, 1024), Y_shape: (242,)\n",
      "12/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/504_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (264, 13, 1024), Y_shape: (264,)\n",
      "13/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/505_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (286, 13, 1024), Y_shape: (286,)\n",
      "14/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/502_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (308, 13, 1024), Y_shape: (308,)\n",
      "15/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/500_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (330, 13, 1024), Y_shape: (330,)\n",
      "16/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/508_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (352, 13, 1024), Y_shape: (352,)\n",
      "17/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/507_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (374, 13, 1024), Y_shape: (374,)\n",
      "18/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/506_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (396, 13, 1024), Y_shape: (396,)\n",
      "19/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/501_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (418, 13, 1024), Y_shape: (418,)\n",
      "20/120 folders downloaded\n",
      "downloaded folder: NR06_20201001_PGS_31_BSD_12/499_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (440, 13, 1024), Y_shape: (440,)\n",
      "21/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/493_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (462, 13, 1024), Y_shape: (462,)\n",
      "22/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/494_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (484, 13, 1024), Y_shape: (484,)\n",
      "23/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/489_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (506, 13, 1024), Y_shape: (506,)\n",
      "24/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/488_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (528, 13, 1024), Y_shape: (528,)\n",
      "25/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/495_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (550, 13, 1024), Y_shape: (550,)\n",
      "26/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/487_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (572, 13, 1024), Y_shape: (572,)\n",
      "27/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/492_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (594, 13, 1024), Y_shape: (594,)\n",
      "28/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/490_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (616, 13, 1024), Y_shape: (616,)\n",
      "29/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/496_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (638, 13, 1024), Y_shape: (638,)\n",
      "30/120 folders downloaded\n",
      "downloaded folder: NR07_20201001_PGS_31_BSD_32/491_2020_10_01.csv\n",
      "Shape of collected datafram: X_shape: (660, 13, 1024), Y_shape: (660,)\n",
      "31/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/460_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (682, 13, 1024), Y_shape: (682,)\n",
      "32/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/456_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (704, 13, 1024), Y_shape: (704,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/459_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (726, 13, 1024), Y_shape: (726,)\n",
      "34/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/451_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (748, 13, 1024), Y_shape: (748,)\n",
      "35/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/458_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (770, 13, 1024), Y_shape: (770,)\n",
      "36/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/457_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (792, 13, 1024), Y_shape: (792,)\n",
      "37/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/455_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (814, 13, 1024), Y_shape: (814,)\n",
      "38/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/452_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (836, 13, 1024), Y_shape: (836,)\n",
      "39/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/453_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (858, 13, 1024), Y_shape: (858,)\n",
      "40/120 folders downloaded\n",
      "downloaded folder: NR09_20200917_PGS_31_BSD_P2/454_2020_09_17.csv\n",
      "Shape of collected datafram: X_shape: (880, 13, 1024), Y_shape: (880,)\n",
      "41/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/423_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (902, 13, 1024), Y_shape: (902,)\n",
      "42/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/424_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (924, 13, 1024), Y_shape: (924,)\n",
      "43/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/422_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (946, 13, 1024), Y_shape: (946,)\n",
      "44/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/420_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (968, 13, 1024), Y_shape: (968,)\n",
      "45/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/421_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (990, 13, 1024), Y_shape: (990,)\n",
      "46/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/415_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1012, 13, 1024), Y_shape: (1012,)\n",
      "47/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/416_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1034, 13, 1024), Y_shape: (1034,)\n",
      "48/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/419_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1056, 13, 1024), Y_shape: (1056,)\n",
      "49/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/418_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1078, 13, 1024), Y_shape: (1078,)\n",
      "50/120 folders downloaded\n",
      "downloaded folder: NR14_20200731_PGS_21_BSD_22/417_2020_07_31.csv\n",
      "Shape of collected datafram: X_shape: (1100, 13, 1024), Y_shape: (1100,)\n",
      "51/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/435_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1122, 13, 1024), Y_shape: (1122,)\n",
      "52/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/428_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1144, 13, 1024), Y_shape: (1144,)\n",
      "53/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/427_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1166, 13, 1024), Y_shape: (1166,)\n",
      "54/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/432_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1188, 13, 1024), Y_shape: (1188,)\n",
      "55/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/433_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1210, 13, 1024), Y_shape: (1210,)\n",
      "56/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/429_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1232, 13, 1024), Y_shape: (1232,)\n",
      "57/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/434_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1254, 13, 1024), Y_shape: (1254,)\n",
      "58/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/436_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1276, 13, 1024), Y_shape: (1276,)\n",
      "59/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/431_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1298, 13, 1024), Y_shape: (1298,)\n",
      "60/120 folders downloaded\n",
      "downloaded folder: NR15_20200901_PGS_21_BSD_12/430_2020_09_01.csv\n",
      "Shape of collected datafram: X_shape: (1320, 13, 1024), Y_shape: (1320,)\n",
      "61/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/447_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1342, 13, 1024), Y_shape: (1342,)\n",
      "62/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/448_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1364, 13, 1024), Y_shape: (1364,)\n",
      "63/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/439_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1386, 13, 1024), Y_shape: (1386,)\n",
      "64/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/440_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1408, 13, 1024), Y_shape: (1408,)\n",
      "65/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/441_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1430, 13, 1024), Y_shape: (1430,)\n",
      "66/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/446_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1452, 13, 1024), Y_shape: (1452,)\n",
      "67/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/444_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1474, 13, 1024), Y_shape: (1474,)\n",
      "68/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/443_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1496, 13, 1024), Y_shape: (1496,)\n",
      "69/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/442_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1518, 13, 1024), Y_shape: (1518,)\n",
      "70/120 folders downloaded\n",
      "downloaded folder: NR16_20200908_PGS_21_BSD_32/445_2020_09_08.csv\n",
      "Shape of collected datafram: X_shape: (1540, 13, 1024), Y_shape: (1540,)\n",
      "71/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/400_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1562, 13, 1024), Y_shape: (1562,)\n",
      "72/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/394_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1584, 13, 1024), Y_shape: (1584,)\n",
      "73/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/393_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1606, 13, 1024), Y_shape: (1606,)\n",
      "74/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/392_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1628, 13, 1024), Y_shape: (1628,)\n",
      "75/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/395_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1650, 13, 1024), Y_shape: (1650,)\n",
      "76/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/397_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1672, 13, 1024), Y_shape: (1672,)\n",
      "77/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/398_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1694, 13, 1024), Y_shape: (1694,)\n",
      "78/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/391_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1716, 13, 1024), Y_shape: (1716,)\n",
      "79/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/399_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1738, 13, 1024), Y_shape: (1738,)\n",
      "80/120 folders downloaded\n",
      "downloaded folder: NR18_20200714_PGS_21_BSD_P2/396_2020_07_14.csv\n",
      "Shape of collected datafram: X_shape: (1760, 13, 1024), Y_shape: (1760,)\n",
      "81/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/290_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1782, 13, 1024), Y_shape: (1782,)\n",
      "82/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/291_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1804, 13, 1024), Y_shape: (1804,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/289_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1826, 13, 1024), Y_shape: (1826,)\n",
      "84/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/294_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1848, 13, 1024), Y_shape: (1848,)\n",
      "85/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/286_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1870, 13, 1024), Y_shape: (1870,)\n",
      "86/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/293_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1892, 13, 1024), Y_shape: (1892,)\n",
      "87/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/292_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1914, 13, 1024), Y_shape: (1914,)\n",
      "88/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/287_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1936, 13, 1024), Y_shape: (1936,)\n",
      "89/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/295_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1958, 13, 1024), Y_shape: (1958,)\n",
      "90/120 folders downloaded\n",
      "downloaded folder: NR23_20200511_PGS_11_BSD_22/288_2020_05_11.csv\n",
      "Shape of collected datafram: X_shape: (1980, 13, 1024), Y_shape: (1980,)\n",
      "91/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/315_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2002, 13, 1024), Y_shape: (2002,)\n",
      "92/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/312_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2024, 13, 1024), Y_shape: (2024,)\n",
      "93/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/313_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2046, 13, 1024), Y_shape: (2046,)\n",
      "94/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/314_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2068, 13, 1024), Y_shape: (2068,)\n",
      "95/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/309_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2090, 13, 1024), Y_shape: (2090,)\n",
      "96/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/316_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2112, 13, 1024), Y_shape: (2112,)\n",
      "97/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/311_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2134, 13, 1024), Y_shape: (2134,)\n",
      "98/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/318_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2156, 13, 1024), Y_shape: (2156,)\n",
      "99/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/310_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2178, 13, 1024), Y_shape: (2178,)\n",
      "100/120 folders downloaded\n",
      "downloaded folder: NR24_20200512_PGS_11_BSD_12/317_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2200, 13, 1024), Y_shape: (2200,)\n",
      "101/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/336_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2222, 13, 1024), Y_shape: (2222,)\n",
      "102/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/339_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2244, 13, 1024), Y_shape: (2244,)\n",
      "103/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/340_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2266, 13, 1024), Y_shape: (2266,)\n",
      "104/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/341_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2288, 13, 1024), Y_shape: (2288,)\n",
      "105/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/338_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2310, 13, 1024), Y_shape: (2310,)\n",
      "106/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/337_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2332, 13, 1024), Y_shape: (2332,)\n",
      "107/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/335_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2354, 13, 1024), Y_shape: (2354,)\n",
      "108/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/332_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2376, 13, 1024), Y_shape: (2376,)\n",
      "109/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/333_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2398, 13, 1024), Y_shape: (2398,)\n",
      "110/120 folders downloaded\n",
      "downloaded folder: NR25_20200512_PGS_11_BSD_32/334_2020_05_12.csv\n",
      "Shape of collected datafram: X_shape: (2420, 13, 1024), Y_shape: (2420,)\n",
      "111/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/379_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2442, 13, 1024), Y_shape: (2442,)\n",
      "112/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/386_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2464, 13, 1024), Y_shape: (2464,)\n",
      "113/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/381_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2486, 13, 1024), Y_shape: (2486,)\n",
      "114/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/380_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2508, 13, 1024), Y_shape: (2508,)\n",
      "115/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/378_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2530, 13, 1024), Y_shape: (2530,)\n",
      "116/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/387_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2552, 13, 1024), Y_shape: (2552,)\n",
      "117/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/385_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2574, 13, 1024), Y_shape: (2574,)\n",
      "118/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/382_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2596, 13, 1024), Y_shape: (2596,)\n",
      "119/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/383_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2618, 13, 1024), Y_shape: (2618,)\n",
      "120/120 folders downloaded\n",
      "downloaded folder: NR27_20200513_PGS_11_BSD_P2/384_2020_05_13.csv\n",
      "Shape of collected datafram: X_shape: (2640, 13, 1024), Y_shape: (2640,)\n"
     ]
    }
   ],
   "source": [
    "window_size = 1024\n",
    "overlap_size = 300\n",
    "features_of_interest = ['S:x_bottom', 'S:y_bottom', 'S:z_bottom', 'S:x_nut', 'S:y_nut', 'S:z_nut', 'S:x_top', 'S:y_top', 'S:z_top', 'S:Nominal_rotational_speed[rad/s]', 'S:Actual_rotational_speed[¬µm/s]', 'S:Actual_position_of_the_position_encoder(dy/dt)[¬µm/s]', 'S:Actual_position_of_the_motor_encoder(dy/dt)[¬µm/s]']\n",
    "list_of_train_BSD_states = [\"1\", \"2\", \"3\", \"4\", \"10\", \"11\", \"12\", \"13\", \"19\", \"20\", \"21\", \"22\"]\n",
    "list_of_test_BSD_states = [\"5\", \"6\", \"7\", \"9\", \"14\", \"15\", \"16\", \"18\", \"23\", \"24\", \"25\", \"27\"]\n",
    "data_path = Path(os.getcwd()).parents[1]\n",
    "data_path = os.path.join(data_path, \"data\")\n",
    "dataloader_split = 0.8\n",
    "batch_size = 4\n",
    "\n",
    "train_loader = Dataloader.create_dataloader(data_path, list_of_train_BSD_states, window_size, overlap_size, features_of_interest, \"train\", dataloader_split, batch_size)\n",
    "test_loader = Dataloader.create_dataloader(data_path, list_of_test_BSD_states, window_size, overlap_size, features_of_interest, \"test\", dataloader_split, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "78ae7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        formula [(W‚àíK+2P)/S]+1.\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=100, stride=1)#input: 1024\n",
    "        self.conv2 = nn.Conv1d(64,32,kernel_size=10, stride = 1, padding=1)#input: [(1024-100+2*0)/1]+1 = 925\n",
    "        self.batch1 =nn.BatchNorm1d(32)#input: [(925-10+2*1)/1]+1 = 918\n",
    "        self.conv3 = nn.Conv1d(32,32,kernel_size=5, stride = 1, padding=1) #input:918\n",
    "        self.batch2 =nn.BatchNorm1d(32)#input: [(918-5+2*1)/1]+1 = 916\n",
    "        self.fc1 = nn.Linear(32*916, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.selu(self.conv1(x)) #conv1\n",
    "        x = self.conv2(x) #conv2\n",
    "        x = F.selu(self.batch1(x)) #batch1\n",
    "        x = self.conv3(x) #conv3\n",
    "        x = F.selu(self.batch2(x)) #batch2\n",
    "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2])) #flatten\n",
    "        #x = self.fc1(x) #linear1\n",
    "        output = x\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "11ce430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "output_size = 4\n",
    "input_fc_size = 32*916\n",
    "\n",
    "# class residual layer: two fully connected layers\n",
    "\n",
    "residual_fc1 = nn.Linear(input_fc_size, input_fc_size)\n",
    "residual_bn1 = nn.BatchNorm1d(input_fc_size)\n",
    "residual_fc2 = nn.Linear(input_fc_size, 128)\n",
    "residual_bn2 = nn.BatchNorm1d(128)\n",
    "residual_fc3 = nn.Linear(128, input_fc_size)\n",
    "residual_fc1.weight.data.normal_(0, 0.005)\n",
    "residual_fc1.bias.data.fill_(0.1)\n",
    "residual_fc2.weight.data.normal_(0, 0.005)\n",
    "residual_fc2.bias.data.fill_(0.1)\n",
    "residual_fc3.weight.data.normal_(0, 0.005)\n",
    "residual_fc3.bias.data.fill_(0.1)\n",
    "feature_residual_layer = nn.Sequential(residual_fc2, nn.ReLU(), residual_fc3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a5a20ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_layer = nn.Linear(input_fc_size, output_size)\n",
    "classifier_layer.weight.data.normal_(0, 0.01)\n",
    "classifier_layer.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "75d69bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_fc22 = nn.Linear(output_size, output_size)\n",
    "residual_bn22 = nn.BatchNorm1d(output_size)\n",
    "residual_fc23 = nn.Linear(output_size, output_size)\n",
    "residual_fc22.weight.data.normal_(0, 0.005)\n",
    "residual_fc22.bias.data.fill_(0.1)\n",
    "residual_fc23.weight.data.normal_(0, 0.005)\n",
    "residual_fc23.bias.data.fill_(0.1)\n",
    "class_residual_layer = nn.Sequential(residual_fc22, nn.ReLU(), residual_fc23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0c7e2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_layer = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7437f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv1d(13, 64, kernel_size=(100,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 32, kernel_size=(10,), stride=(1,), padding=(1,))\n",
      "  (batch1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(1,))\n",
      "  (batch2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=29312, out_features=4, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=29312, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=29312, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "Linear(in_features=29312, out_features=4, bias=True)\n",
      "Softmax(dim=None)\n"
     ]
    }
   ],
   "source": [
    "model = CNN(input_size, output_size)\n",
    "print(model)\n",
    "print(feature_residual_layer)\n",
    "print(class_residual_layer)\n",
    "print(classifier_layer)\n",
    "print(softmax_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "13883a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EntropyLoss(prediction):\n",
    "    \"\"\"\n",
    "    Entropy is a measure of impurity. In classification purity is prefered, because the more distinguishable \n",
    "    4 classes are, the more reliable the classification will be. In this sense the impurity of the prediction on\n",
    "    the unlabeled targer domain is included in the loss \n",
    "    \n",
    "    INPUT:\n",
    "    @ prediction: model prediction for unlabeled target domain\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = prediction.ge(0.0000001)\n",
    "    mask_out = torch.masked_select(prediction, mask)\n",
    "    entropy = - (torch.sum(mask_out * torch.log(mask_out)))\n",
    "    return entropy / float(prediction.size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "e242227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0]) + int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "    \n",
    "    #unsqueeze 2d array of shape (8,32*916) to shape (1,8,32*916)\n",
    "    #expand to shape (8,8,32*916) by copying 2d array of shape (8,32*916) 8 times in frist dimension of 3d array\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    \n",
    "    #unsqueeze 2d array of shape (8,32*916) to shape (8,1,32*916)\n",
    "    #expand to shape (8,8,32*916) by copying each row from 2d array of shape (8,32*916) 8 times to a 2d array of shape (8,32*916). Doing that for each row and concatenating the resulting 2d arrays of shape shape (8,32*916) in the first dimension of a 3d array of shape shape (8,8,32*916)\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    \n",
    "    #L2 Norm: for nominator of exp\n",
    "    #difference between all possible elements in between and within source and target domain\n",
    "    #feature difference between two elements are summed up to one value\n",
    "    L2_distance = ((total0 - total1) ** 2).sum(2)\n",
    "    \n",
    "    #Bandwith: for denominator of exp\n",
    "    #Bandwith selection has crucial effect on estimate.\n",
    "        #small bandwith: undersmoothed since it contains too many spurious data artifacts\n",
    "        #big bandwith: oversmoothed since it obscures much of the underlying structure\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        \n",
    "        #total difference/ n_samples **2 -n_samples\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples ** 2 - n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)  # /len(kernel_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bb6724a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "                              kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "    loss = 0\n",
    "    for i in range(batch_size):\n",
    "        s1, s2 = i, (i + 1) % batch_size\n",
    "        t1, t2 = s1 + batch_size, s2 + batch_size\n",
    "        loss += kernels[s1, s2] + kernels[t1, t2]\n",
    "        loss -= kernels[s1, t2] + kernels[s2, t1]\n",
    "    return loss / float(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1e1026a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n",
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rg/g_9b4q1j0h94scy_c8tdgd980000gn/T/ipykernel_1892/1985733582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha_off\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtransfer_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta_off\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;31m#add up losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer_graph = SummaryWriter('runs/Dataloader2/graph')\n",
    "writer_train = SummaryWriter('runs/Dataloader2/train')\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 50\n",
    "learning_rate = 0.008\n",
    "len_data_loader = len(train_loader[\"train\"])\n",
    "\n",
    "#define loss parameter\n",
    "loss_collected = 0\n",
    "alpha_off = 1.5\n",
    "beta_off = 0.1\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loader = iter(train_loader[\"train\"]) #generate new iter element for each epoch\n",
    "    epoch_test_loader = iter(test_loader)\n",
    "    for i in range(len_data_loader):\n",
    "\n",
    "        windows_source, labels_source = epoch_train_loader.next() #batch_size number of windows and labels from source domain\n",
    "        windows_target, _ = epoch_test_loader.next() #batch_size number of windows from target domain\n",
    "        \n",
    "        batch_size = len(labels_source) #take length of shorter dataoader which is the one from source domain (reason:train, val split)\n",
    "        windows = torch.cat((windows_source, windows_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "    \n",
    "        ########Forward pass########\n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "        \n",
    "\n",
    "        #collect loss\n",
    "        classifier_loss = criterion(output_base[:batch_size, :], labels_source) #Loss just for source domain since we do just have labels there\n",
    "        loss_collected += classifier_loss\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        softmax_output_base = softmax_layer(output_base) #activation of class_num output for entropy loss\n",
    "        total_softmax_residual = softmax_layer(total_output_residual)\n",
    "        entropy_loss = EntropyLoss(total_softmax_residual[batch_size:, :]) #entropy loss for all unlabeled target elements\n",
    "        \n",
    "        \n",
    "        # alignment of L task-specific feature layers (Here, we have one layer)\n",
    "        transfer_loss = MMD(features_base[:batch_size, :],\n",
    "                            total_feature_residual[batch_size:, :]) #apply MMD between CNN feature extractor and attention module output just for unlabeled target elements\n",
    "        # alignment of softmax layer\n",
    "        transfer_loss += MMD(softmax_output_base[:batch_size, :],\n",
    "                             total_softmax_residual[batch_size:, :],\n",
    "                             kernel_num=1, fix_sigma=1.68) #apply MMD between fully connected layer and feature correction module output just for unlabeled target elements\n",
    "\n",
    "        ########Backward pass########\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = classifier_loss + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    ############## TENSORBOARD ########################\n",
    "    running_loss = loss_collected / len_data_loader\n",
    "    loss_collected = 0\n",
    "    writer_train.add_scalar(f'training loss', running_loss, epoch)\n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "de079c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network: 33.40909090909091 %\n",
      "Accuracy of BSD_11: 25.90909090909091 %\n",
      "Accuracy of BSD_21: 29.848484848484848 %\n",
      "Accuracy of BSD_31: 34.09090909090909 %\n",
      "Accuracy of BSD_P1: 43.78787878787879 %\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "with torch.no_grad():\n",
    "    classes = ['BSD_11', 'BSD_21', 'BSD_31', 'BSD_P1']\n",
    "    \n",
    "    #collect information about labels, predictions\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(4)]\n",
    "    n_class_samples = [0 for i in range(4)]\n",
    "    n_class_samples_out = [0 for i in range(4)]\n",
    "    \n",
    "    #iterate through bateches in test_loader\n",
    "    for window, labels in test_loader:\n",
    "        #make predictions for each batch\n",
    "        features_base = model(window.float())\n",
    "        outputs = classifier_layer(features_base)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "        for i in range(batch_size):\n",
    "            if len(labels)==4:\n",
    "                label = labels[i]\n",
    "                output = torch.argmax(outputs[i])\n",
    "                if label == output:\n",
    "                    n_correct+=1\n",
    "                    n_class_correct[label]+=1\n",
    "                \n",
    "                n_samples+=1\n",
    "                n_class_samples[label]+=1\n",
    "                n_class_samples_out[output]+=1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #calculate total accuracy\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "    \n",
    "    #calculate class accuracy\n",
    "    for i in range(4):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "66b5f697",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:103: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 successfull\n",
      "Epoch 2/300 successfull\n",
      "Epoch 3/300 successfull\n",
      "Epoch 4/300 successfull\n",
      "Epoch 5/300 successfull\n",
      "Epoch 6/300 successfull\n",
      "Epoch 7/300 successfull\n",
      "Epoch 8/300 successfull\n",
      "Epoch 9/300 successfull\n",
      "Epoch 10/300 successfull\n",
      "Epoch 11/300 successfull\n",
      "Epoch 12/300 successfull\n",
      "Epoch 13/300 successfull\n",
      "Epoch 14/300 successfull\n",
      "Epoch 15/300 successfull\n",
      "Epoch 16/300 successfull\n",
      "Epoch 17/300 successfull\n",
      "Epoch 18/300 successfull\n",
      "Epoch 19/300 successfull\n",
      "Epoch 20/300 successfull\n",
      "Epoch 21/300 successfull\n",
      "Epoch 22/300 successfull\n",
      "Epoch 23/300 successfull\n",
      "Epoch 24/300 successfull\n",
      "Epoch 25/300 successfull\n",
      "Epoch 26/300 successfull\n",
      "Epoch 27/300 successfull\n",
      "Epoch 28/300 successfull\n",
      "Epoch 29/300 successfull\n",
      "Epoch 30/300 successfull\n",
      "Epoch 31/300 successfull\n",
      "Epoch 32/300 successfull\n",
      "Epoch 33/300 successfull\n",
      "Epoch 34/300 successfull\n",
      "Epoch 35/300 successfull\n",
      "Epoch 36/300 successfull\n",
      "Epoch 37/300 successfull\n",
      "Epoch 38/300 successfull\n",
      "Epoch 39/300 successfull\n",
      "Epoch 40/300 successfull\n",
      "Epoch 41/300 successfull\n",
      "Epoch 42/300 successfull\n",
      "Epoch 43/300 successfull\n",
      "Epoch 44/300 successfull\n",
      "Epoch 45/300 successfull\n",
      "Epoch 46/300 successfull\n",
      "Epoch 47/300 successfull\n",
      "Epoch 48/300 successfull\n",
      "Epoch 49/300 successfull\n",
      "Epoch 50/300 successfull\n",
      "Epoch 51/300 successfull\n",
      "Epoch 52/300 successfull\n",
      "Epoch 53/300 successfull\n",
      "Epoch 54/300 successfull\n",
      "Epoch 55/300 successfull\n",
      "Epoch 56/300 successfull\n",
      "Epoch 57/300 successfull\n",
      "Epoch 58/300 successfull\n",
      "Epoch 59/300 successfull\n",
      "Epoch 60/300 successfull\n",
      "Epoch 61/300 successfull\n",
      "Epoch 62/300 successfull\n",
      "Epoch 63/300 successfull\n",
      "Epoch 64/300 successfull\n",
      "Epoch 65/300 successfull\n",
      "Epoch 66/300 successfull\n",
      "Epoch 67/300 successfull\n",
      "Epoch 68/300 successfull\n",
      "Epoch 69/300 successfull\n",
      "Epoch 70/300 successfull\n",
      "Epoch 71/300 successfull\n",
      "Epoch 72/300 successfull\n",
      "Epoch 73/300 successfull\n",
      "Epoch 74/300 successfull\n",
      "Epoch 75/300 successfull\n",
      "Epoch 76/300 successfull\n",
      "Epoch 77/300 successfull\n",
      "Epoch 78/300 successfull\n",
      "Epoch 79/300 successfull\n",
      "Epoch 80/300 successfull\n",
      "Epoch 81/300 successfull\n",
      "Epoch 82/300 successfull\n",
      "Epoch 83/300 successfull\n",
      "Epoch 84/300 successfull\n",
      "Epoch 85/300 successfull\n",
      "Epoch 86/300 successfull\n",
      "Epoch 87/300 successfull\n",
      "Epoch 88/300 successfull\n",
      "Epoch 89/300 successfull\n",
      "Epoch 90/300 successfull\n",
      "Epoch 91/300 successfull\n",
      "Epoch 92/300 successfull\n",
      "Epoch 93/300 successfull\n",
      "Epoch 94/300 successfull\n",
      "Epoch 95/300 successfull\n",
      "Epoch 96/300 successfull\n",
      "Epoch 97/300 successfull\n",
      "Epoch 98/300 successfull\n",
      "Epoch 99/300 successfull\n",
      "Epoch 100/300 successfull\n",
      "Epoch 101/300 successfull\n",
      "Epoch 102/300 successfull\n",
      "Epoch 103/300 successfull\n",
      "Epoch 104/300 successfull\n",
      "Epoch 105/300 successfull\n",
      "Epoch 106/300 successfull\n",
      "Epoch 107/300 successfull\n",
      "Epoch 108/300 successfull\n",
      "Epoch 109/300 successfull\n",
      "Epoch 110/300 successfull\n",
      "Epoch 111/300 successfull\n",
      "Epoch 112/300 successfull\n",
      "Epoch 113/300 successfull\n",
      "Epoch 114/300 successfull\n",
      "Epoch 115/300 successfull\n",
      "Epoch 116/300 successfull\n",
      "Epoch 117/300 successfull\n",
      "Epoch 118/300 successfull\n",
      "Epoch 119/300 successfull\n",
      "Epoch 120/300 successfull\n",
      "Epoch 121/300 successfull\n",
      "Epoch 122/300 successfull\n",
      "Epoch 123/300 successfull\n",
      "Epoch 124/300 successfull\n",
      "Epoch 125/300 successfull\n",
      "Epoch 126/300 successfull\n",
      "Epoch 127/300 successfull\n",
      "Epoch 128/300 successfull\n",
      "Epoch 129/300 successfull\n",
      "Epoch 130/300 successfull\n",
      "Epoch 131/300 successfull\n",
      "Epoch 132/300 successfull\n",
      "Epoch 133/300 successfull\n",
      "Epoch 134/300 successfull\n",
      "Epoch 135/300 successfull\n",
      "Epoch 136/300 successfull\n",
      "Epoch 137/300 successfull\n",
      "Epoch 138/300 successfull\n",
      "Epoch 139/300 successfull\n",
      "Epoch 140/300 successfull\n",
      "Epoch 141/300 successfull\n",
      "Epoch 142/300 successfull\n",
      "Epoch 143/300 successfull\n",
      "Epoch 144/300 successfull\n",
      "Epoch 145/300 successfull\n",
      "Epoch 146/300 successfull\n",
      "Epoch 147/300 successfull\n",
      "Epoch 148/300 successfull\n",
      "Epoch 149/300 successfull\n",
      "Epoch 150/300 successfull\n",
      "Epoch 151/300 successfull\n",
      "Epoch 152/300 successfull\n",
      "Epoch 153/300 successfull\n",
      "Epoch 154/300 successfull\n",
      "Epoch 155/300 successfull\n",
      "Epoch 156/300 successfull\n",
      "Epoch 157/300 successfull\n",
      "Epoch 158/300 successfull\n",
      "Epoch 159/300 successfull\n",
      "Epoch 160/300 successfull\n",
      "Epoch 161/300 successfull\n",
      "Epoch 162/300 successfull\n",
      "Epoch 163/300 successfull\n",
      "Epoch 164/300 successfull\n",
      "Epoch 165/300 successfull\n",
      "Epoch 166/300 successfull\n",
      "Epoch 167/300 successfull\n",
      "Epoch 168/300 successfull\n",
      "Epoch 169/300 successfull\n",
      "Epoch 170/300 successfull\n",
      "Epoch 171/300 successfull\n",
      "Epoch 172/300 successfull\n",
      "Epoch 173/300 successfull\n",
      "Epoch 174/300 successfull\n",
      "Epoch 175/300 successfull\n",
      "Epoch 176/300 successfull\n",
      "Epoch 177/300 successfull\n",
      "Epoch 178/300 successfull\n",
      "Epoch 179/300 successfull\n",
      "Epoch 180/300 successfull\n",
      "Epoch 181/300 successfull\n",
      "Epoch 182/300 successfull\n",
      "Epoch 183/300 successfull\n",
      "Epoch 184/300 successfull\n",
      "Epoch 185/300 successfull\n",
      "Epoch 186/300 successfull\n",
      "Epoch 187/300 successfull\n",
      "Epoch 188/300 successfull\n",
      "Epoch 189/300 successfull\n",
      "Epoch 190/300 successfull\n",
      "Epoch 191/300 successfull\n",
      "Epoch 192/300 successfull\n",
      "Epoch 193/300 successfull\n",
      "Epoch 194/300 successfull\n",
      "Epoch 195/300 successfull\n",
      "Epoch 196/300 successfull\n",
      "Epoch 197/300 successfull\n",
      "Epoch 198/300 successfull\n",
      "Epoch 199/300 successfull\n",
      "Epoch 200/300 successfull\n",
      "Epoch 201/300 successfull\n",
      "Epoch 202/300 successfull\n",
      "Epoch 203/300 successfull\n",
      "Epoch 204/300 successfull\n",
      "Epoch 205/300 successfull\n",
      "Epoch 206/300 successfull\n",
      "Epoch 207/300 successfull\n",
      "Epoch 208/300 successfull\n",
      "Epoch 209/300 successfull\n",
      "Epoch 210/300 successfull\n",
      "Epoch 211/300 successfull\n",
      "Epoch 212/300 successfull\n",
      "Epoch 213/300 successfull\n",
      "Epoch 214/300 successfull\n",
      "Epoch 215/300 successfull\n",
      "Epoch 216/300 successfull\n",
      "Epoch 217/300 successfull\n",
      "Epoch 218/300 successfull\n",
      "Epoch 219/300 successfull\n",
      "Epoch 220/300 successfull\n",
      "Epoch 221/300 successfull\n",
      "Epoch 222/300 successfull\n",
      "Epoch 223/300 successfull\n",
      "Epoch 224/300 successfull\n",
      "Epoch 225/300 successfull\n",
      "Epoch 226/300 successfull\n",
      "Epoch 227/300 successfull\n",
      "Epoch 228/300 successfull\n",
      "Epoch 229/300 successfull\n",
      "Epoch 230/300 successfull\n",
      "Epoch 231/300 successfull\n",
      "Epoch 232/300 successfull\n",
      "Epoch 233/300 successfull\n",
      "Epoch 234/300 successfull\n",
      "Epoch 235/300 successfull\n",
      "Epoch 236/300 successfull\n",
      "Epoch 237/300 successfull\n",
      "Epoch 238/300 successfull\n",
      "Epoch 239/300 successfull\n",
      "Epoch 240/300 successfull\n",
      "Epoch 241/300 successfull\n",
      "Epoch 242/300 successfull\n",
      "Epoch 243/300 successfull\n",
      "Epoch 244/300 successfull\n",
      "Epoch 245/300 successfull\n",
      "Epoch 246/300 successfull\n",
      "Epoch 247/300 successfull\n",
      "Epoch 248/300 successfull\n",
      "Epoch 249/300 successfull\n",
      "Epoch 250/300 successfull\n",
      "Epoch 251/300 successfull\n",
      "Epoch 252/300 successfull\n",
      "Epoch 253/300 successfull\n",
      "Epoch 254/300 successfull\n",
      "Epoch 255/300 successfull\n",
      "Epoch 256/300 successfull\n",
      "Epoch 257/300 successfull\n",
      "Epoch 258/300 successfull\n",
      "Epoch 259/300 successfull\n",
      "Epoch 260/300 successfull\n",
      "Epoch 261/300 successfull\n",
      "Epoch 262/300 successfull\n",
      "Epoch 263/300 successfull\n",
      "Epoch 264/300 successfull\n",
      "Epoch 265/300 successfull\n",
      "Epoch 266/300 successfull\n",
      "Epoch 267/300 successfull\n",
      "Epoch 268/300 successfull\n",
      "Epoch 269/300 successfull\n",
      "Epoch 270/300 successfull\n",
      "Epoch 271/300 successfull\n",
      "Epoch 272/300 successfull\n",
      "Epoch 273/300 successfull\n",
      "Epoch 274/300 successfull\n",
      "Epoch 275/300 successfull\n",
      "Epoch 276/300 successfull\n",
      "Epoch 277/300 successfull\n",
      "Epoch 278/300 successfull\n",
      "Epoch 279/300 successfull\n",
      "Epoch 280/300 successfull\n",
      "Epoch 281/300 successfull\n",
      "Epoch 282/300 successfull\n",
      "Epoch 283/300 successfull\n",
      "Epoch 284/300 successfull\n",
      "Epoch 285/300 successfull\n",
      "Epoch 286/300 successfull\n",
      "Epoch 287/300 successfull\n",
      "Epoch 288/300 successfull\n",
      "Epoch 289/300 successfull\n",
      "Epoch 290/300 successfull\n",
      "Epoch 291/300 successfull\n",
      "Epoch 292/300 successfull\n",
      "Epoch 293/300 successfull\n",
      "Epoch 294/300 successfull\n",
      "Epoch 295/300 successfull\n",
      "Epoch 296/300 successfull\n",
      "Epoch 297/300 successfull\n",
      "Epoch 298/300 successfull\n",
      "Epoch 299/300 successfull\n",
      "Epoch 300/300 successfull\n"
     ]
    }
   ],
   "source": [
    "writer_train = SummaryWriter('runs/Dataloader2/train')\n",
    "writer_test = SummaryWriter('runs/Dataloader2/test')\n",
    "\n",
    "writer = {}\n",
    "writer[\"train\"] = writer_train\n",
    "writer[\"test\"] = writer_test\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 300\n",
    "learning_rate = 0.008\n",
    "len_data_loader = {}\n",
    "len_data_loader[\"train\"] = len(train_loader[\"train\"])\n",
    "len_data_loader[\"test\"] = len(test_loader)\n",
    "\n",
    "\n",
    "#define loss parameter\n",
    "total_loss_collected = 0\n",
    "alpha_off = 1.5\n",
    "beta_off = 0.1\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#collect accuracy for each batch\n",
    "accuracy_list={}\n",
    "accuracy_list['train']=[]\n",
    "accuracy_list['test']=[]\n",
    "\n",
    "#collect loss for each batch\n",
    "loss_collected = 0\n",
    "loss_list = {}\n",
    "loss_list['train']=[]\n",
    "loss_list['test']=[]\n",
    "\n",
    "    \n",
    "#collect information about labels, predictions\n",
    "n_correct = 0\n",
    "n_samples = 0\n",
    "n_class_correct = [0 for i in range(4)]\n",
    "n_class_samples = [0 for i in range(4)]\n",
    "n_class_samples_out = [0 for i in range(4)]\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train(True)\n",
    "    feature_residual_layer.train(True)\n",
    "    classifier_layer.train(True)\n",
    "    class_residual_layer.train(True)\n",
    "    \n",
    "    epoch_train_loader = iter(train_loader[\"train\"]) #generate new iter element for each epoch\n",
    "    epoch_test_loader = iter(test_loader)\n",
    "    for i in range(len_data_loader[\"train\"]):\n",
    "\n",
    "        windows_source, labels_source = epoch_train_loader.next() #batch_size number of windows and labels from source domain\n",
    "        windows_target, _ = epoch_test_loader.next() #batch_size number of windows from target domain\n",
    "        \n",
    "        batch_size = len(labels_source) #take length of shorter dataoader which is the one from source domain (reason:train, val split)\n",
    "        windows = torch.cat((windows_source, windows_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "    \n",
    "        ########Forward pass########\n",
    "        \n",
    "        #Domain Conditioned Channel Attention#\n",
    "        features_base = model(windows.float()) # Convolutional Feature extractor\n",
    "        features_residual = feature_residual_layer(features_base) # attention module\n",
    "        total_feature_residual = features_base + features_residual #apply attention module\n",
    "        output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "                    \n",
    "        #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "        for i in range(batch_size):\n",
    "            label = labels_source[i]\n",
    "            output = torch.argmax(output_base[i,:])\n",
    "            if label == output:\n",
    "                n_correct+=1\n",
    "                n_class_correct[label]+=1\n",
    "\n",
    "            n_samples+=1\n",
    "            n_class_samples[label]+=1\n",
    "            n_class_samples_out[output]+=1\n",
    "            \n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        writer['train'].add_scalar(f'accuracy', acc, epoch)\n",
    "        accuracy_list['train'].append(acc)\n",
    "        \n",
    "        #reset information about labels, predictions\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(4)]\n",
    "        n_class_samples = [0 for i in range(4)]\n",
    "        n_class_samples_out = [0 for i in range(4)]\n",
    "        \n",
    "        \n",
    "        #collect loss\n",
    "        classifier_loss = criterion(output_base[:batch_size, :], labels_source) #Loss just for source domain since we do just have labels there\n",
    "        loss_collected += classifier_loss\n",
    "        \n",
    "        #Domain Conditioned Feature Correction#\n",
    "        residual_output_base = classifier_layer(total_feature_residual) #Fully Connected Classifier Layer after appleid attention module \n",
    "        output_residual = class_residual_layer(residual_output_base) #feature correction module\n",
    "        total_output_residual = residual_output_base + output_residual #apply feature correction module\n",
    "        softmax_output_base = softmax_layer(output_base) #activation of class_num output for entropy loss\n",
    "        total_softmax_residual = softmax_layer(total_output_residual)\n",
    "        entropy_loss = EntropyLoss(total_softmax_residual[batch_size:, :]) #entropy loss for all unlabeled target elements\n",
    "        \n",
    "        # alignment of L task-specific feature layers (Here, we have one layer)\n",
    "        #apply MMD between CNN feature extractor and attention module output just for unlabeled target elements\n",
    "        transfer_loss = MMD(features_base[:batch_size, :],total_feature_residual[batch_size:, :])\n",
    "        # alignment of softmax layer\n",
    "        #apply MMD between fully connected layer and feature correction module output just for unlabeled target elements\n",
    "        transfer_loss += MMD(softmax_output_base[:batch_size, :],total_softmax_residual[batch_size:, :], kernel_num=1, fix_sigma=1.68)\n",
    "\n",
    "        ########Backward pass########\n",
    "        optimizer.zero_grad()\n",
    "        total_loss = classifier_loss + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "        total_loss_collected+=total_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    loss_list['train'].append(total_loss_collected/len_data_loader[\"train\"])\n",
    "    writer[\"train\"].add_scalar(f'training loss', total_loss_collected/len_data_loader[\"train\"], epoch)\n",
    "    total_loss_collected = 0    \n",
    "        \n",
    "        \n",
    "    model.train(False)\n",
    "    feature_residual_layer.train(False)\n",
    "    classifier_layer.train(False)\n",
    "    class_residual_layer.train(False)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for windows_target, labels_target in test_loader:\n",
    "            #make predictions for each batch\n",
    "            \n",
    "            \n",
    "            ########Forward pass########\n",
    "            #Domain Conditioned Channel Attention#\n",
    "            features_base = model(windows_target.float()) # Convolutional Feature extractor\n",
    "            features_residual = feature_residual_layer(features_base) # attention module\n",
    "            total_feature_residual = features_base + features_residual #apply attention module\n",
    "            output_base = classifier_layer(features_base) #Fully Connected Classifier Layer\n",
    "\n",
    "\n",
    "            #collect loss\n",
    "            classifier_loss = criterion(output_base, labels) #Loss just for source domain since we do just have labels there\n",
    "            \n",
    "\n",
    "            ########Backward pass########\n",
    "            total_loss = classifier_loss# + alpha_off * transfer_loss + beta_off * entropy_loss #add up losses\n",
    "            total_loss_collected+=total_loss\n",
    "            \n",
    "            \n",
    "            #for each element in batch check if prediction is correct and collect total and correct predictions and labels\n",
    "            for i in range(batch_size):\n",
    "                if len(labels)==4:\n",
    "                    label = labels[i]\n",
    "                    output = torch.argmax(output_base[i])\n",
    "                    if label == output:\n",
    "                        n_correct+=1\n",
    "                        n_class_correct[label]+=1\n",
    "\n",
    "                n_samples+=1\n",
    "                n_class_samples[label]+=1\n",
    "                n_class_samples_out[output]+=1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "        loss_list['test'].append(total_loss_collected/len_data_loader[\"test\"])\n",
    "        writer[\"test\"].add_scalar(f'training loss', total_loss_collected/len_data_loader[\"test\"], epoch)\n",
    "        total_loss_collected = 0\n",
    "\n",
    "\n",
    "        #calculate total accuracy\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        writer['test'].add_scalar(f'accuracy', acc, epoch)\n",
    "        accuracy_list['test'].append(acc)\n",
    "        \n",
    "        \"\"\"\n",
    "        #calculate class accuracy\n",
    "        for i in range(4):\n",
    "            acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "            print(f'Accuracy of {classes[i]}: {acc} %')\n",
    "        \"\"\"\n",
    "        \n",
    "        #reset information about labels, predictions\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        n_class_correct = [0 for i in range(4)]\n",
    "        n_class_samples = [0 for i in range(4)]\n",
    "        n_class_samples_out = [0 for i in range(4)]\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e23cece1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[660, 660, 660, 660]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7aaea513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 660, 660, 1320]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_samples_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b1f27a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 155, 178, 340]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9b337473",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.ones(6,4)\n",
    "for i in range(test.shape[0]):\n",
    "    test[i,:]+=i\n",
    "for j in range(test.shape[1]):\n",
    "    test[:,j]+=j\n",
    "test1 = test.unsqueeze(0)\n",
    "test1 = test1.expand(test.shape[0], test.shape[0], test.shape[1])\n",
    "test2 = test.unsqueeze(1)\n",
    "test2 = test2.expand(test.shape[0], test.shape[0], test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "79de6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [2., 3., 4., 5.],\n",
      "        [3., 4., 5., 6.],\n",
      "        [4., 5., 6., 7.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6a3536e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]],\n",
      "\n",
      "        [[1., 2., 3., 4.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [6., 7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8b89f831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.],\n",
      "         [1., 2., 3., 4.]],\n",
      "\n",
      "        [[2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.],\n",
      "         [2., 3., 4., 5.]],\n",
      "\n",
      "        [[3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.],\n",
      "         [3., 4., 5., 6.]],\n",
      "\n",
      "        [[4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.],\n",
      "         [4., 5., 6., 7.]],\n",
      "\n",
      "        [[5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.],\n",
      "         [5., 6., 7., 8.]],\n",
      "\n",
      "        [[6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.],\n",
      "         [6., 7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "36b4eab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.],\n",
      "         [ 5.,  5.,  5.,  5.]],\n",
      "\n",
      "        [[-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.],\n",
      "         [ 4.,  4.,  4.,  4.]],\n",
      "\n",
      "        [[-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.],\n",
      "         [ 3.,  3.,  3.,  3.]],\n",
      "\n",
      "        [[-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.],\n",
      "         [ 2.,  2.,  2.,  2.]],\n",
      "\n",
      "        [[-4., -4., -4., -4.],\n",
      "         [-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.],\n",
      "         [ 1.,  1.,  1.,  1.]],\n",
      "\n",
      "        [[-5., -5., -5., -5.],\n",
      "         [-4., -4., -4., -4.],\n",
      "         [-3., -3., -3., -3.],\n",
      "         [-2., -2., -2., -2.],\n",
      "         [-1., -1., -1., -1.],\n",
      "         [ 0.,  0.,  0.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "print((test1-test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7089f044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   4.,   8.,  12.,  16.,  20.],\n",
      "        [ -4.,   0.,   4.,   8.,  12.,  16.],\n",
      "        [ -8.,  -4.,   0.,   4.,   8.,  12.],\n",
      "        [-12.,  -8.,  -4.,   0.,   4.,   8.],\n",
      "        [-16., -12.,  -8.,  -4.,   0.,   4.],\n",
      "        [-20., -16., -12.,  -8.,  -4.,   0.]])\n"
     ]
    }
   ],
   "source": [
    "print((test1-test2).sum(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7f58ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.sum((test1-test2).sum(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a6110e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "tensor([[[ 1.1890e-02,  5.4555e-03, -2.7445e-02,  ...,  1.2281e-02,\n",
      "          -7.8437e-03,  2.2083e-02],\n",
      "         [ 1.3511e-02,  1.3682e-02,  1.3075e-02,  ...,  8.0766e-03,\n",
      "           2.2623e-02,  1.2111e-02],\n",
      "         [ 1.3993e-02, -2.6534e-02,  1.1586e-02,  ...,  1.4887e-02,\n",
      "           2.0653e-02,  2.2189e-02],\n",
      "         ...,\n",
      "         [ 3.5323e-03,  3.9464e-03,  1.0062e-02,  ...,  2.4773e-02,\n",
      "          -1.6287e-02,  2.7165e-02],\n",
      "         [-3.7622e-01,  4.0350e-01,  1.0938e-01,  ..., -1.0257e-01,\n",
      "          -5.8266e-02,  3.4897e-01],\n",
      "         [-1.0374e-01, -2.3422e-03,  4.0168e-01,  ...,  6.2887e-02,\n",
      "          -3.7084e-01,  7.9371e-02]],\n",
      "\n",
      "        [[-2.1931e-02, -5.9448e-04, -1.7292e-02,  ..., -1.5165e-02,\n",
      "           1.3063e-02, -1.9931e-02],\n",
      "         [-1.6830e-02,  2.4009e-02, -2.3674e-02,  ...,  2.6150e-02,\n",
      "          -1.0254e-02,  1.7687e-02],\n",
      "         [-9.9820e-03, -5.3584e-03,  2.0857e-02,  ..., -1.4631e-02,\n",
      "          -1.5062e-02,  9.7501e-05],\n",
      "         ...,\n",
      "         [-6.8892e-03, -9.0674e-03,  2.1505e-02,  ...,  1.9065e-02,\n",
      "           9.7701e-03,  2.0178e-02],\n",
      "         [ 1.6724e-01, -2.6792e-01,  2.3408e-01,  ...,  8.8753e-02,\n",
      "           1.3980e-01, -2.8182e-01],\n",
      "         [ 9.8131e-02, -1.8374e-01,  7.4063e-02,  ..., -3.1107e-02,\n",
      "           7.5337e-02,  1.8262e-02]],\n",
      "\n",
      "        [[-1.9244e-02, -1.7492e-02,  2.6423e-02,  ...,  1.4404e-02,\n",
      "           2.5985e-02, -2.0622e-02],\n",
      "         [-1.6937e-02, -2.5193e-02,  1.4087e-02,  ..., -1.1833e-02,\n",
      "          -2.1368e-02,  2.5981e-02],\n",
      "         [ 3.0784e-03,  2.3775e-02, -1.7640e-02,  ...,  1.0522e-02,\n",
      "           2.2846e-02,  2.1270e-03],\n",
      "         ...,\n",
      "         [-7.3134e-03, -3.1615e-03,  1.0000e-02,  ..., -7.9093e-03,\n",
      "          -1.2271e-02, -1.3162e-02],\n",
      "         [ 6.6893e-02, -9.0389e-02, -1.2454e-01,  ..., -5.5556e-02,\n",
      "          -1.9990e-01, -2.6608e-02],\n",
      "         [-3.4605e-02, -1.0644e-01, -1.9605e-01,  ..., -6.0583e-02,\n",
      "          -7.7708e-02, -8.5744e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1797e-02, -1.7495e-02,  1.5895e-02,  ...,  3.2765e-04,\n",
      "           1.8057e-02, -1.8151e-03],\n",
      "         [-2.6844e-02, -2.1646e-02,  2.3466e-02,  ...,  1.0532e-02,\n",
      "           1.8812e-02, -1.7501e-02],\n",
      "         [ 1.1719e-02,  6.8626e-03,  8.9687e-03,  ...,  1.4990e-02,\n",
      "           1.6244e-02, -5.1906e-04],\n",
      "         ...,\n",
      "         [ 9.6290e-03,  1.1811e-02, -1.6168e-02,  ...,  2.8621e-02,\n",
      "           2.1923e-02, -6.6281e-03],\n",
      "         [-3.6484e-02, -1.2908e-01,  3.1238e-01,  ...,  2.0002e-01,\n",
      "           3.0802e-02,  1.4361e-01],\n",
      "         [-1.8873e-01,  1.0573e-01, -4.1396e-02,  ..., -1.5093e-01,\n",
      "           1.3738e-01, -3.0094e-02]],\n",
      "\n",
      "        [[-1.4511e-02, -4.7531e-03, -1.0820e-02,  ...,  7.2765e-03,\n",
      "           2.8186e-03,  1.1821e-02],\n",
      "         [-1.4291e-03,  2.0176e-02, -9.6198e-03,  ...,  2.0763e-02,\n",
      "          -1.3153e-02,  3.1719e-03],\n",
      "         [-1.6770e-02,  1.0776e-03, -2.1189e-02,  ...,  1.7363e-02,\n",
      "           1.3084e-02, -2.0949e-02],\n",
      "         ...,\n",
      "         [ 2.1117e-02,  1.8607e-02, -2.5632e-02,  ...,  8.1134e-03,\n",
      "          -2.6885e-03,  8.7551e-03],\n",
      "         [ 2.6612e-01, -3.4655e-01, -1.2277e-01,  ..., -8.5492e-02,\n",
      "          -5.0338e-02,  5.4414e-02],\n",
      "         [ 1.2634e-01, -1.1413e-01,  4.1138e-02,  ...,  2.0142e-01,\n",
      "          -2.1250e-01, -1.0364e-01]],\n",
      "\n",
      "        [[ 2.0993e-02,  2.0899e-02, -2.7665e-02,  ...,  4.5545e-03,\n",
      "          -2.3739e-03,  2.6540e-02],\n",
      "         [-2.3280e-02,  2.7508e-02, -2.5649e-02,  ...,  4.8684e-03,\n",
      "           7.1045e-03,  1.7705e-02],\n",
      "         [ 4.1595e-03, -8.5009e-03,  1.0760e-02,  ...,  1.0056e-02,\n",
      "           2.6307e-02, -5.5712e-03],\n",
      "         ...,\n",
      "         [ 9.9189e-03,  1.9642e-02,  7.8023e-03,  ..., -1.0052e-02,\n",
      "           2.2402e-02, -2.2272e-02],\n",
      "         [ 1.0563e-01, -2.9189e-01, -2.4202e-01,  ...,  1.8071e-01,\n",
      "          -5.1732e-02,  2.8367e-02],\n",
      "         [ 5.4859e-02,  1.5261e-01,  2.6976e-02,  ...,  5.8194e-02,\n",
      "          -3.3381e-01,  2.2766e-02]]])\n",
      "conv1.bias\n",
      "tensor([ 0.0215, -0.0277,  0.0138, -0.0191,  0.0096, -0.0231, -0.0109, -0.0257,\n",
      "         0.0187, -0.0039, -0.0116, -0.0072, -0.0259, -0.0102,  0.0170, -0.0221,\n",
      "         0.0175,  0.0251, -0.0065,  0.0001, -0.0273,  0.0175, -0.0041, -0.0019,\n",
      "         0.0028, -0.0144,  0.0267, -0.0110, -0.0122,  0.0207,  0.0186,  0.0234,\n",
      "        -0.0066,  0.0225, -0.0067, -0.0172,  0.0239,  0.0185,  0.0148, -0.0276,\n",
      "        -0.0123,  0.0212, -0.0244, -0.0013,  0.0165, -0.0175, -0.0191, -0.0018,\n",
      "         0.0044,  0.0099,  0.0127, -0.0185, -0.0062,  0.0183, -0.0042, -0.0279,\n",
      "        -0.0028,  0.0097,  0.0113, -0.0194, -0.0057, -0.0234, -0.0133, -0.0065])\n",
      "conv2.weight\n",
      "tensor([[[-1.4315e-01,  9.2267e-02, -8.0937e-02,  ...,  4.6654e-02,\n",
      "           2.7156e-01, -1.0499e-01],\n",
      "         [ 1.9748e-01, -2.0624e-01,  1.3146e-01,  ...,  1.4933e-01,\n",
      "           4.2593e-02, -1.7323e-01],\n",
      "         [ 5.6452e-03,  4.7620e-02,  1.9397e-01,  ..., -1.3410e-01,\n",
      "           3.9936e-03, -1.7607e-01],\n",
      "         ...,\n",
      "         [-6.2394e-02, -5.6638e-02,  3.6078e-02,  ...,  1.9993e-01,\n",
      "          -9.9270e-02,  1.1287e-01],\n",
      "         [ 1.0385e-01, -2.5153e-01,  8.2987e-02,  ..., -3.0005e-02,\n",
      "           3.4198e-02,  5.5822e-02],\n",
      "         [-2.2361e-01,  4.7580e-02, -3.2520e-02,  ...,  6.0295e-02,\n",
      "          -2.1182e-01,  1.2618e-01]],\n",
      "\n",
      "        [[ 6.7101e-02, -7.9366e-02, -4.5095e-02,  ..., -8.2384e-02,\n",
      "           9.5786e-02, -8.7946e-02],\n",
      "         [ 2.7768e-02, -2.4361e-01,  7.0593e-02,  ..., -4.7156e-02,\n",
      "           4.8659e-02, -6.5696e-02],\n",
      "         [ 1.3634e-01,  1.1696e-02,  1.3666e-02,  ...,  1.0693e-01,\n",
      "           1.2410e-01, -1.9099e-02],\n",
      "         ...,\n",
      "         [ 2.2267e-01, -1.3363e-01, -3.5286e-02,  ...,  2.8196e-02,\n",
      "           2.1591e-01,  1.7356e-01],\n",
      "         [ 1.8648e-02, -1.2389e-01,  4.4503e-02,  ...,  1.2759e-01,\n",
      "          -2.2903e-01,  8.1815e-02],\n",
      "         [-5.0864e-02, -2.7675e-02, -5.5457e-03,  ..., -4.2524e-02,\n",
      "          -3.8269e-02, -1.4520e-02]],\n",
      "\n",
      "        [[ 2.8581e-02, -5.8958e-02, -9.5781e-02,  ..., -7.0566e-02,\n",
      "          -2.9397e-01,  3.0899e-01],\n",
      "         [-1.5502e-01, -1.7036e-01,  2.0879e-02,  ..., -7.3698e-02,\n",
      "           1.9543e-01, -4.0873e-02],\n",
      "         [ 1.1489e-02, -6.7083e-02,  1.1649e-01,  ...,  4.9042e-02,\n",
      "           2.3982e-01, -1.3827e-01],\n",
      "         ...,\n",
      "         [-2.7015e-03,  3.6154e-02,  1.5325e-01,  ...,  2.5246e-03,\n",
      "           2.3283e-01,  2.8363e-01],\n",
      "         [-1.2366e-02, -8.8565e-02,  3.8031e-02,  ...,  4.2363e-02,\n",
      "          -2.5900e-02,  1.4032e-01],\n",
      "         [-2.2821e-01, -4.7971e-02, -1.1303e-01,  ...,  1.4022e-01,\n",
      "          -2.2738e-01, -1.2376e-03]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.2104e-03, -6.6995e-02, -1.6945e-02,  ..., -2.8547e-02,\n",
      "           3.4924e-02, -1.0730e-02],\n",
      "         [-2.8202e-02, -1.7369e-03, -3.1680e-02,  ...,  8.6279e-02,\n",
      "          -4.3328e-02, -1.1469e-01],\n",
      "         [ 3.9718e-02,  8.3857e-02,  6.6354e-02,  ...,  2.6402e-02,\n",
      "          -7.6006e-03,  4.9176e-02],\n",
      "         ...,\n",
      "         [-5.6264e-02,  6.1075e-02, -2.9394e-03,  ..., -5.9042e-02,\n",
      "          -8.7865e-02, -1.2233e-01],\n",
      "         [ 7.9158e-02,  6.1987e-02, -3.0495e-03,  ..., -1.4728e-02,\n",
      "           6.6875e-03, -5.1567e-02],\n",
      "         [ 1.6835e-02,  5.8428e-02,  4.4091e-02,  ...,  2.1617e-02,\n",
      "           4.0890e-02,  1.2876e-02]],\n",
      "\n",
      "        [[-9.5641e-02, -9.5626e-02, -3.2025e-03,  ..., -2.1723e-02,\n",
      "           6.1819e-02,  2.0061e-02],\n",
      "         [ 5.7516e-02, -3.0940e-03,  6.5183e-02,  ...,  4.7580e-02,\n",
      "          -5.7534e-03, -6.9045e-05],\n",
      "         [-1.3951e-01, -6.2557e-02,  9.7090e-02,  ...,  4.4121e-02,\n",
      "          -1.1541e-02, -7.9127e-03],\n",
      "         ...,\n",
      "         [-3.5273e-02, -2.1056e-02, -3.3869e-03,  ...,  1.0620e-01,\n",
      "           4.9943e-02,  6.1548e-02],\n",
      "         [ 2.2207e-02,  6.5699e-02, -1.4100e-02,  ..., -7.6641e-02,\n",
      "          -2.7718e-03,  2.2677e-02],\n",
      "         [-5.3077e-02, -1.8821e-02, -6.4650e-03,  ..., -1.8331e-02,\n",
      "           5.6697e-02,  1.6488e-02]],\n",
      "\n",
      "        [[ 2.9778e-02,  9.2471e-02,  2.6142e-02,  ..., -1.6309e-01,\n",
      "           1.6759e-01,  3.2498e-02],\n",
      "         [-2.2117e-03, -1.9548e-02, -1.0040e-01,  ...,  7.0825e-02,\n",
      "          -1.0572e-01, -4.6921e-02],\n",
      "         [-3.1228e-02, -4.3263e-02, -2.7185e-02,  ...,  6.6729e-03,\n",
      "          -2.5536e-02, -2.5158e-02],\n",
      "         ...,\n",
      "         [ 1.0378e-01, -3.0083e-02, -4.6989e-02,  ...,  1.6990e-02,\n",
      "           4.1530e-02, -8.3125e-02],\n",
      "         [ 1.4295e-02, -1.3001e-02, -3.8248e-02,  ..., -1.6166e-02,\n",
      "           9.0549e-02, -5.6678e-02],\n",
      "         [-6.6664e-02, -9.1019e-02, -1.1094e-02,  ..., -7.4279e-02,\n",
      "          -7.5879e-02, -1.4681e-01]]])\n",
      "conv2.bias\n",
      "tensor([ 0.0054,  0.0237,  0.0325,  0.0333, -0.0243,  0.0258, -0.0065,  0.0304,\n",
      "         0.0004, -0.0071, -0.0323, -0.0176, -0.0212,  0.0322, -0.0094,  0.0267,\n",
      "        -0.0155,  0.0146, -0.0127,  0.0307,  0.0281, -0.0371,  0.0121,  0.0132,\n",
      "        -0.0127,  0.0303, -0.0162,  0.0346,  0.0200, -0.0337,  0.0175, -0.0001])\n",
      "batch1.weight\n",
      "tensor([1.5587, 1.5742, 2.0631, 1.4126, 2.2354, 1.0592, 2.7218, 1.6030, 1.5299,\n",
      "        1.2988, 1.9991, 0.8776, 1.2194, 0.9938, 0.9370, 0.8095, 1.4425, 1.4590,\n",
      "        1.3253, 0.7524, 1.5667, 1.1807, 1.1604, 0.5432, 1.1558, 0.9429, 1.2676,\n",
      "        1.1566, 1.0642, 1.2428, 0.8866, 1.1275])\n",
      "batch1.bias\n",
      "tensor([-0.7067, -0.6218, -1.0377, -0.7009, -1.1870, -0.2023, -1.1330, -0.7498,\n",
      "        -0.7485, -0.5358, -0.8996, -0.2696, -0.4570, -0.3927, -0.2590, -0.1496,\n",
      "        -0.7596, -0.5421, -0.5183, -0.1478, -0.7093, -0.4863, -0.4659, -0.0707,\n",
      "        -0.5594, -0.3432, -0.3425, -0.4552, -0.3394, -0.3132, -0.3795, -0.5532])\n",
      "batch1.running_mean\n",
      "tensor([-8111.8877, -6877.9917, -9159.4736, -7236.3271, -9213.3594, -2641.4219,\n",
      "        -7933.0518, -5024.7554, -7631.6118, -9331.2441, -7914.2056, -5267.0757,\n",
      "        -3468.1333, -7141.5337, -5583.4453,  1073.1553, -2449.5947, -8663.8213,\n",
      "        -3983.8093,  1003.0170, -5944.3120, -4155.4727, -2597.4377,   510.2956,\n",
      "        -4157.8643, -4891.4854, -4026.9131, -8324.7852, -4328.3462, -8576.4805,\n",
      "        -5943.1099, -4446.5464])\n",
      "batch1.running_var\n",
      "tensor([1.4266e+08, 1.4377e+08, 2.3668e+08, 1.7948e+08, 2.2404e+08, 1.3662e+08,\n",
      "        3.1574e+08, 1.4575e+08, 1.7024e+08, 4.2896e+08, 2.4514e+08, 1.0812e+08,\n",
      "        1.4471e+08, 1.3230e+08, 1.1154e+08, 7.4390e+07, 8.3643e+07, 2.1715e+08,\n",
      "        1.1027e+08, 7.0426e+07, 1.1701e+08, 1.2863e+08, 6.8539e+07, 1.0591e+08,\n",
      "        8.4226e+07, 1.5473e+08, 4.5671e+08, 1.7363e+08, 1.2194e+08, 2.3619e+09,\n",
      "        1.4814e+08, 8.9281e+07])\n",
      "batch1.num_batches_tracked\n",
      "tensor(212170)\n",
      "conv3.weight\n",
      "tensor([[[-0.1919,  0.2394, -0.0200, -0.3388, -0.0032],\n",
      "         [-0.3987,  0.1571, -0.0257, -0.0099,  0.3325],\n",
      "         [-0.2339,  0.1523,  0.0381, -0.0240,  0.0246],\n",
      "         ...,\n",
      "         [ 0.2042,  0.2553, -0.0377, -0.1294, -0.1974],\n",
      "         [ 0.1137,  0.1173,  0.0981, -0.1170,  0.0962],\n",
      "         [ 0.0690,  0.0122,  0.2298,  0.0220, -0.2148]],\n",
      "\n",
      "        [[-0.0732, -0.0289,  0.0803,  0.1740,  0.0863],\n",
      "         [ 0.0226,  0.2131, -0.3189, -0.0836,  0.2688],\n",
      "         [-0.2830,  0.1897,  0.2610,  0.0768, -0.4050],\n",
      "         ...,\n",
      "         [ 0.0343, -0.1826,  0.0847,  0.0534,  0.0379],\n",
      "         [-0.0638,  0.0606,  0.0052, -0.0381,  0.0664],\n",
      "         [ 0.1283,  0.0496, -0.0843, -0.1102, -0.0048]],\n",
      "\n",
      "        [[ 0.1265,  0.0406, -0.3205,  0.3290, -0.1315],\n",
      "         [ 0.0783, -0.0671, -0.0345,  0.0690,  0.0829],\n",
      "         [-0.3470,  0.2551, -0.1229,  0.3263, -0.1430],\n",
      "         ...,\n",
      "         [-0.1231,  0.0045,  0.0312, -0.1438,  0.0698],\n",
      "         [-0.2413, -0.0287,  0.0850,  0.0478, -0.0765],\n",
      "         [ 0.0352, -0.1892, -0.1043,  0.2992,  0.0824]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0596,  0.0687, -0.3487, -0.0949,  0.3426],\n",
      "         [-0.2071,  0.1685,  0.1585, -0.0867, -0.0890],\n",
      "         [-0.0304, -0.1517, -0.0060,  0.2504, -0.3274],\n",
      "         ...,\n",
      "         [-0.0615, -0.1678, -0.1054, -0.0842,  0.3017],\n",
      "         [ 0.0503,  0.0345, -0.1600,  0.0439,  0.3258],\n",
      "         [-0.0567,  0.1745,  0.0713, -0.3107, -0.1841]],\n",
      "\n",
      "        [[-0.1331,  0.3425, -0.3054,  0.3708, -0.0585],\n",
      "         [-0.3655,  0.2978, -0.0263,  0.1744, -0.2262],\n",
      "         [-0.0572, -0.1981, -0.1120,  0.0823,  0.2993],\n",
      "         ...,\n",
      "         [ 0.0607,  0.0413, -0.0014, -0.0596,  0.0869],\n",
      "         [-0.0588,  0.0669,  0.1625,  0.1034,  0.0674],\n",
      "         [ 0.2089, -0.2516,  0.0533, -0.0419, -0.0729]],\n",
      "\n",
      "        [[-0.1498,  0.1677, -0.2109,  0.1405,  0.0644],\n",
      "         [-0.2104,  0.4137, -0.1106,  0.3276, -0.4119],\n",
      "         [-0.1898,  0.0431,  0.3075, -0.1094,  0.0489],\n",
      "         ...,\n",
      "         [-0.1456,  0.0826, -0.0583, -0.0155, -0.0063],\n",
      "         [ 0.0356,  0.0296, -0.0850,  0.0353,  0.1969],\n",
      "         [ 0.0130, -0.0650,  0.0068,  0.1737,  0.1117]]])\n",
      "conv3.bias\n",
      "tensor([-0.0270,  0.0238, -0.0113, -0.0590, -0.0251,  0.0264,  0.0233,  0.0171,\n",
      "        -0.0290, -0.0466,  0.0759,  0.0350, -0.0766, -0.0644,  0.0557,  0.0451,\n",
      "         0.0449,  0.0214, -0.0606,  0.0591,  0.0406,  0.0245,  0.0342,  0.0566,\n",
      "         0.0761, -0.0083, -0.0181,  0.0432,  0.0440,  0.0073, -0.0188, -0.0182])\n",
      "batch2.weight\n",
      "tensor([2.7755, 2.4411, 3.9512, 2.5367, 3.2439, 2.5058, 2.3259, 3.2102, 1.9975,\n",
      "        1.5728, 2.0657, 2.6128, 3.4378, 3.1128, 3.1797, 2.6034, 2.6213, 2.7551,\n",
      "        3.0024, 2.2480, 2.7841, 2.8374, 2.6083, 2.4560, 3.2574, 2.9930, 3.3269,\n",
      "        2.8107, 3.2443, 2.5252, 2.5596, 2.0022])\n",
      "batch2.bias\n",
      "tensor([ 0.0253,  0.1403,  0.1955,  0.0851, -0.0208,  0.1616, -0.0890,  0.1376,\n",
      "        -0.1081,  0.2477, -0.0339,  0.0138,  0.0062,  0.1324, -0.2012, -0.1328,\n",
      "         0.0668, -0.1994, -0.0782, -0.1371, -0.0453, -0.1174, -0.1142,  0.3960,\n",
      "         0.1135,  0.2355,  0.3177,  0.1662,  0.3397,  0.1117,  0.0911, -0.0153])\n",
      "batch2.running_mean\n",
      "tensor([-0.1516, -0.4851,  0.0484,  0.0700, -0.0508,  0.2465, -0.4263, -0.2357,\n",
      "         0.0984,  0.3009,  0.1888, -0.0908, -0.3744, -0.4036,  0.1147,  0.0817,\n",
      "         0.2265,  0.0258, -0.3263,  0.1637, -0.0030,  0.2951,  0.1706,  0.3823,\n",
      "         0.2563,  0.0451, -0.2694,  0.1132,  0.3686,  0.2995, -0.2644, -0.0101])\n",
      "batch2.running_var\n",
      "tensor([5.1761, 4.1749, 7.7932, 4.7887, 4.8065, 5.0813, 3.8415, 5.2295, 3.7969,\n",
      "        2.7050, 3.3003, 4.3352, 6.1249, 5.3320, 4.8583, 4.5063, 5.2363, 5.0970,\n",
      "        5.2142, 4.0024, 5.0209, 4.0770, 4.5552, 4.3644, 5.4318, 6.2560, 5.8101,\n",
      "        5.1142, 6.7138, 5.7689, 4.5040, 3.8292])\n",
      "batch2.num_batches_tracked\n",
      "tensor(212169)\n",
      "fc1.weight\n",
      "tensor([[ 0.0050, -0.0006, -0.0017,  ...,  0.0025,  0.0040,  0.0024],\n",
      "        [-0.0037, -0.0054,  0.0025,  ...,  0.0030, -0.0052, -0.0047],\n",
      "        [-0.0052,  0.0015,  0.0032,  ..., -0.0031, -0.0045,  0.0048],\n",
      "        [-0.0036, -0.0035,  0.0031,  ...,  0.0016, -0.0055,  0.0020]])\n",
      "fc1.bias\n",
      "tensor([-0.0010,  0.0018,  0.0015,  0.0052])\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "for name, params in state_dict.items():\n",
    "    print(name)\n",
    "    print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e94618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
