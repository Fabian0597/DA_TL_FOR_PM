{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_curve(freq, ampl, freq_noise, ampl_noise, window_size):\n",
    "    freq = random.gauss(freq, freq_noise) #add noise to frequency\n",
    "    ampl = random.gauss(ampl, ampl_noise) #add noise to amplitude\n",
    "    time = np.linspace(0, 10*np.pi, window_size)\n",
    "    x = ampl*np.cos(freq*time)\n",
    "    noise = np.random.normal(random.uniform(-1,0), random.uniform(0,1), window_size)\n",
    "    x+=noise\n",
    "    x = np.expand_dims(x, axis = 0) #expand to get 2d array (features, window length)\n",
    "    x = np.expand_dims(x, axis = 0) #expand to get 3d array to store 2d elements\n",
    "    #print(f\"freq: {freq}, ampl:{ampl}\")\n",
    "    #fig1 = plt.figure()\n",
    "    #plt.plot(time, x[0,0,:])\n",
    "    #plt.show()\n",
    "    #fig1.savefig(f'CLASS:{CLASS}, iteration: {it}')\n",
    "    \n",
    "    return x\n",
    "\n",
    "def create_data_window(n, frequencies, amplitudes, freq_noise, ampl_noise, window_size):\n",
    "   \n",
    "    X_data_class_1_domain_1 = np.empty((0,1,window_size))\n",
    "    X_data_class_2_domain_1 = np.empty((0,1,window_size))\n",
    "    X_data_class_1_domain_2 = np.empty((0,1,window_size))\n",
    "    X_data_class_2_domain_2 = np.empty((0,1,window_size))\n",
    "    \n",
    "    for i in range(n):\n",
    "        X_data_class_1_domain_1 = np.append(X_data_class_1_domain_1, create_curve(frequencies[0], amplitudes[0], freq_noise, ampl_noise, window_size), axis = 0) \n",
    "        X_data_class_2_domain_1 = np.append(X_data_class_2_domain_1, create_curve(frequencies[1], amplitudes[1], freq_noise, ampl_noise, window_size), axis = 0)\n",
    "        X_data_class_1_domain_2 = np.append(X_data_class_1_domain_2, create_curve(frequencies[2], amplitudes[2], freq_noise, ampl_noise, window_size), axis = 0)\n",
    "        X_data_class_2_domain_2 = np.append(X_data_class_2_domain_2, create_curve(frequencies[3], amplitudes[3], freq_noise, ampl_noise, window_size), axis = 0)\n",
    "        \n",
    "        #print(i)\n",
    "        #print((X_data_class_1_domain_1))\n",
    "        \n",
    "    n_samples = np.shape(X_data_class_2_domain_1)[0]*2  \n",
    "    \n",
    "    y_data_class_1_domain_1 = np.asarray([0]*np.shape(X_data_class_1_domain_1)[0])\n",
    "    y_data_class_2_domain_1 = np.asarray([1]*np.shape(X_data_class_2_domain_1)[0])\n",
    "    y_data_class_1_domain_2 = np.asarray([0]*np.shape(X_data_class_1_domain_2)[0])\n",
    "    y_data_class_2_domain_2 = np.asarray([1]*np.shape(X_data_class_2_domain_2)[0])\n",
    "    \n",
    "    X_data_source = np.concatenate((X_data_class_1_domain_1, X_data_class_2_domain_1), axis = 0)\n",
    "    y_data_source = np.concatenate((y_data_class_1_domain_1, y_data_class_2_domain_1), axis = 0)\n",
    "    X_data_target = np.concatenate((X_data_class_1_domain_2, X_data_class_2_domain_2), axis = 0)\n",
    "    y_data_target = np.concatenate((y_data_class_1_domain_2, y_data_class_2_domain_2), axis = 0)\n",
    "    \n",
    "    \n",
    "    X_data_source = torch.from_numpy(X_data_source)\n",
    "    y_data_source = torch.from_numpy(y_data_source)\n",
    "    X_data_target = torch.from_numpy(X_data_target)\n",
    "    y_data_target = torch.from_numpy(y_data_target)\n",
    "    \n",
    "    return n_samples, X_data_source, y_data_source, X_data_target, y_data_target\n",
    "\"\"\"\n",
    "#TEST\n",
    "frequencies = [1,4,1.4,3.6]\n",
    "amplitudes = [6,2,5,4]\n",
    "freq_noise = 0.3\n",
    "ampl_noise = 2\n",
    "window_size = 1000\n",
    "n_samples, X_data_source, y_data_source, X_data_target, y_data_target = create_data_window(1000, frequencies, amplitudes, freq_noise, ampl_noise, window_size)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4a68ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_Dummy_Source_Window(Dataset):\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        n = 8000\n",
    "        frequencies = [1,4,1.9,3.1]#[1,4,1.6,3.4]\n",
    "        amplitudes = [6,2,5,4]\n",
    "        freq_noise = 0.5\n",
    "        ampl_noise = 2\n",
    "        window_size = 1000\n",
    "        self.n_samples, self.x_data, self.y_data, _, _ = create_data_window(n, frequencies, amplitudes, freq_noise, ampl_noise, window_size)\n",
    "        \n",
    "        \n",
    "                  \n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class Dataset_Dummy_Target_Window(Dataset):\n",
    "\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        n = 8000\n",
    "        frequencies = [1,4,1.9,3.1]\n",
    "        amplitudes = [6,2,5,4]\n",
    "        freq_noise = 0.5\n",
    "        ampl_noise = 2\n",
    "        window_size = 1000\n",
    "        self.n_samples, _, _, self.x_data, self.y_data = create_data_window(n, frequencies, amplitudes, freq_noise, ampl_noise, window_size)\n",
    "        \n",
    "        \n",
    "                  \n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b9a732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#dataloader\n",
    "\n",
    "dataset_source = Dataset_Dummy_Source_Window()\n",
    "\n",
    "# define train/val dimensions\n",
    "ce_size_source = int(0.6 * len(dataset_source))\n",
    "validation_size_source = int(0.2 * len(dataset_source))\n",
    "mmd_size_source = int(0.2 * len(dataset_source))\n",
    "\n",
    "\n",
    "ce_dataset_source, validation_dataset_source, mmd_dataset_source = torch.utils.data.random_split(dataset_source, [ce_size_source, validation_size_source, mmd_size_source])\n",
    "batch_size = 64\n",
    "ce_loader_source = DataLoader(dataset=ce_dataset_source,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "validation_loader_source = DataLoader(dataset=validation_dataset_source,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "mmd_loader_source = DataLoader(dataset=mmd_dataset_source,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_target = Dataset_Dummy_Target_Window()\n",
    "\n",
    "# define train/val dimensions\n",
    "ce_size_target = int(0.6 * len(dataset_target))\n",
    "validation_size_target = int(0.2 * len(dataset_target))\n",
    "mmd_size_target = int(0.2 * len(dataset_target))\n",
    "\n",
    "ce_dataset_target, validation_dataset_target, mmd_dataset_target = torch.utils.data.random_split(dataset_target, [ce_size_target, validation_size_target, mmd_size_target])\n",
    "batch_size = 64\n",
    "ce_loader_target = DataLoader(dataset=ce_dataset_target,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "validation_loader_target = DataLoader(dataset=validation_dataset_target,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "mmd_loader_target = DataLoader(dataset=mmd_dataset_target,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "source_loader = {}\n",
    "source_loader[\"ce\"] = ce_loader_source\n",
    "source_loader[\"val\"] = validation_loader_source\n",
    "source_loader[\"mmd\"] = mmd_loader_target\n",
    "\n",
    "target_loader = {}\n",
    "target_loader[\"ce\"] = ce_loader_target\n",
    "target_loader[\"val\"] = validation_loader_target\n",
    "target_loader[\"mmd\"] = mmd_loader_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, input_fc_size, hidden_fc_size_1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_size, 64, kernel_size=100, stride=1)#input: ((1000+2*0-(100-1)-1)/1)+1 = 901\n",
    "        self.pool1 = nn.MaxPool1d(4, stride=3) #((901+2*0-1*(4-1)-1)/3)+1 = 300\n",
    "        self.conv2 = nn.Conv1d(64,32,kernel_size=10, stride = 1, padding=1)#input: ((300+2*1-(10-1)-1)/1)+1 = 293\n",
    "        self.batch1 =nn.BatchNorm1d(32) #293\n",
    "        self.pool2 = nn.MaxPool1d(5, stride=3) #((293+2*0-1*(5-1)-1)/3)+1 = 97\n",
    "        self.conv3 = nn.Conv1d(32,16,kernel_size=5, stride = 1, padding=1) #((97+2*1-(5-1)-1)/1)+1 = 95\n",
    "        self.batch2 =nn.BatchNorm1d(16) #95\n",
    "        self.pool3 = nn.MaxPool1d(5, stride=3) #((95+2*0-1*(5-1)-1)/3)+1 = 31\n",
    "        self.fc1 = nn.Linear(input_fc_size, hidden_fc_size_1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) #conv1\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.pool1(x) #pool1\n",
    "        x = self.conv2(x) #conv2\n",
    "        x = self.batch1(x) #batch1\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.pool2(x) #pool2\n",
    "        x = self.conv3(x) #conv3\n",
    "        x = self.batch2(x) #batch2\n",
    "        x = F.relu(x) #relu\n",
    "        x = self.pool3(x) #pool3\n",
    "        x_flatten = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[2])) #flatten\n",
    "        x = torch.nn.functional.normalize(x)\n",
    "        x_fc1 = self.fc1(x_flatten) #fc1\n",
    "\n",
    "\n",
    "        return x_flatten, x_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58060be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_fc_size_1, hidden_fc_size_2, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc2 = nn.Linear(hidden_fc_size_1, hidden_fc_size_2)\n",
    "        self.fc3 = nn.Linear(hidden_fc_size_2, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc2 = self.fc2(x) #fc2\n",
    "        x_fc3 = self.fc3(x_fc2) #fc3\n",
    "        \n",
    "        return x_fc2, x_fc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "#input_fc_size = 32*892 #25*40 \n",
    "input_fc_size = 16*31\n",
    "hidden_fc_size_1 = 50\n",
    "hidden_fc_size_2 = 3\n",
    "output_size = 2\n",
    "\n",
    "model_cnn = CNN(input_size, input_fc_size, hidden_fc_size_1)\n",
    "\n",
    "model_fc = Classifier(hidden_fc_size_1, hidden_fc_size_2, output_size)\n",
    "\n",
    "print(model_cnn)\n",
    "\n",
    "print(model_fc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cde266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from mmd_loss import MMD_loss\n",
    "class MMD_loss(nn.Module):\n",
    "    def __init__(self, fix_sigma = None, kernel_mul = 2.0, kernel_num = 5):\n",
    "        super(MMD_loss, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.fix_sigma = fix_sigma\n",
    "        return\n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma = None):\n",
    "        n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "        total = torch.cat([source, target], dim=0)\n",
    "        \n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        L2_distance = ((total0-total1)**2).sum(2) \n",
    "        bandwidth_list = self.fix_sigma\n",
    "        kernel_val = [torch.exp(-L2_distance / sigma) for sigma in self.fix_sigma]\n",
    "        return sum(kernel_val)\n",
    "\n",
    "    def forward(self, source, target):\n",
    "        batch_size = int(source.size()[0])\n",
    "        kernels = self.gaussian_kernel(source, target, kernel_mul=self.kernel_mul, kernel_num=self.kernel_num, fix_sigma=self.fix_sigma)\n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        loss = torch.mean(XX + YY - XY -YX)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b419d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def forward_intra_inter_mmd(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag_phase, GAMMA_inter_class, GAMMA_intra_class):\n",
    "        \n",
    "        #Feature extraction\n",
    "        outputs_cnn, x_fc1 = model_cnn(data.float())\n",
    "        x_fc2, x_fc3 = model_fc(x_fc1)\n",
    "        \n",
    "        batch_size = len(labels_source)         \n",
    "        \n",
    "        #Classification\n",
    "        source_x_flatten = outputs_cnn[:batch_size, :]\n",
    "        target_x_flatten = outputs_cnn[batch_size:, :]\n",
    "        x_src = x_fc1[:batch_size, :]\n",
    "        x_tar = x_fc1[batch_size:, :]\n",
    "        source_out = x_fc2[:batch_size, :]\n",
    "        target_out = x_fc2[batch_size:, :]\n",
    "        source_pred = x_fc3[:batch_size, :]\n",
    "        target_pred = x_fc3[batch_size:, :]\n",
    "        \n",
    "        #CE loss\n",
    "        source_ce_loss = criterion(source_pred, labels_source)\n",
    "        target_ce_loss = criterion(target_pred, labels_target)\n",
    "\n",
    "        #collect information about labels, predictions to calculate accuracy\n",
    "        n_correct_source = 0\n",
    "        n_correct_target = 0\n",
    "        n_samples_source = 0\n",
    "        n_samples_target = 0\n",
    "        \n",
    "        # list of classified latent space features in flattend CNN\n",
    "        class_0_source_x_flatten = torch.empty((0,source_x_flatten.size()[1]))\n",
    "        class_1_source_x_flatten = torch.empty((0,source_x_flatten.size()[1]))\n",
    "        class_0_target_x_flatten = torch.empty((0,target_x_flatten.size()[1]))\n",
    "        class_1_target_x_flatten = torch.empty((0,target_x_flatten.size()[1]))\n",
    "        \n",
    "        # list of classified latent space features in FC1\n",
    "        class_0_source_out = torch.empty((0,source_out.size()[1]))\n",
    "        class_1_source_out = torch.empty((0,source_out.size()[1]))\n",
    "        class_0_target_out = torch.empty((0,target_out.size()[1]))\n",
    "        class_1_target_out = torch.empty((0,target_out.size()[1]))\n",
    "        \n",
    "        # list of classified latent space features in FC2\n",
    "        class_0_source_x = torch.empty((0,x_src.size()[1]))\n",
    "        class_1_source_x = torch.empty((0,x_src.size()[1]))\n",
    "        class_0_target_x = torch.empty((0,x_tar.size()[1]))\n",
    "        class_1_target_x = torch.empty((0,x_tar.size()[1]))\n",
    "        \n",
    "        \n",
    "        #SOURCE iteration through batch\n",
    "        for i in range(len(labels_source)):\n",
    "            \n",
    "            #get label and prediction\n",
    "            label_source = labels_source[i]\n",
    "            output_source = torch.argmax(source_pred[i])\n",
    "            if label_source == output_source: #correct prediction\n",
    "                n_correct_source+=1\n",
    "            n_samples_source+=1\n",
    "            \n",
    "            #sort x_src and source_out depending on their classes\n",
    "            if label_source == 0:\n",
    "                class_0_source_x_flatten = torch.cat((class_0_source_x_flatten, torch.unsqueeze(source_x_flatten[i,:],0)), 0)\n",
    "                class_0_source_out = torch.cat((class_0_source_out, torch.unsqueeze(source_out[i,:],0)),0)\n",
    "                class_0_source_x = torch.cat((class_0_source_x, torch.unsqueeze(x_src[i,:],0)), 0)\n",
    "            elif label_source == 1:\n",
    "                class_1_source_x_flatten = torch.cat((class_1_source_x_flatten, torch.unsqueeze(source_x_flatten[i,:],0)), 0)\n",
    "                class_1_source_out = torch.cat((class_1_source_out, torch.unsqueeze(source_out[i,:],0)), 0)\n",
    "                class_1_source_x = torch.cat((class_1_source_x, torch.unsqueeze(x_src[i,:],0)), 0)\n",
    "        acc_total_source = 100.0 * n_correct_source / n_samples_source #source accuracy\n",
    "            \n",
    "            \n",
    "            \n",
    "        #TARGET iteration through batch\n",
    "        for i in range(len(labels_target)):\n",
    "            \n",
    "            #check correct prediction\n",
    "            label_target = labels_target[i]\n",
    "            output_target = torch.argmax(target_pred[i])#correct prediction\n",
    "            if label_target == output_target:\n",
    "                n_correct_target+=1\n",
    "            n_samples_target+=1\n",
    "            #sort x_tar and target_out depending on their classes\n",
    "            if label_target == 0:\n",
    "                class_0_target_x_flatten = torch.cat((class_0_target_x_flatten, torch.unsqueeze(target_x_flatten[i,:],0)), 0)\n",
    "                class_0_target_out = torch.cat((class_0_target_out, torch.unsqueeze(target_out[i,:],0)),0)\n",
    "                class_0_target_x = torch.cat((class_0_target_x, torch.unsqueeze(x_tar[i,:],0)), 0)\n",
    "            elif label_target == 1:\n",
    "                class_1_target_x_flatten = torch.cat((class_1_target_x_flatten, torch.unsqueeze(target_x_flatten[i,:],0)), 0)\n",
    "                class_1_target_out = torch.cat((class_1_target_out, torch.unsqueeze(target_out[i,:], 0)), 0)\n",
    "                class_1_target_x = torch.cat((class_1_target_x, torch.unsqueeze(x_tar[i,:], 0)), 0)\n",
    "        \n",
    "        acc_total_target = 100.0 * n_correct_target / n_samples_target #target accuracy\n",
    "        \n",
    "        \n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        \n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_0 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_0_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_1 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_1_target_x_flatten[:min_1_flatten,:])\n",
    "\n",
    "        mmd_x_class_0_0 = MMD_loss.forward(class_0_source_x[:min_0_x,:],class_0_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_1 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_1_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_0 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_0_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_1 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_1_target_out[:min_1_out,:])\n",
    "        \n",
    "        \n",
    "        \n",
    "        mmd_loss_inter_class = mmd_x_class_0_0 + mmd_x_class_1_1 + mmd_out_class_0_0 + mmd_out_class_1_1 + mmd_flatten_class_0_0 + mmd_flatten_class_1_1\n",
    "        #mmd_loss_inter_class = mmd_flatten_class_0_0 + mmd_flatten_class_1_1\n",
    "\n",
    "        #Intraclass MMD loss\n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_1 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_1_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_0 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_0_target_x_flatten[:min_1_flatten,:])\n",
    "        \n",
    "        mmd_x_class_0_1= MMD_loss.forward(class_0_source_x[:min_0_x,:], class_1_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_0 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_0_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_1 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_1_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_0 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_0_target_out[:min_1_out,:])\n",
    "        \n",
    "        mmd_loss_intra_class = mmd_x_class_0_1 + mmd_x_class_1_0 + mmd_out_class_0_1 + mmd_out_class_1_0 + mmd_flatten_class_0_1 + mmd_flatten_class_1_0\n",
    "        #mmd_loss_intra_class = mmd_flatten_class_0_1 + mmd_flatten_class_1_0\n",
    "        \n",
    "        #total mmd loss\n",
    "        mmd_loss = GAMMA_inter_class * mmd_loss_inter_class - GAMMA_intra_class * mmd_loss_intra_class\n",
    "        \n",
    "        if MMD_loss_flag_phase == True:\n",
    "            loss = source_ce_loss + mmd_loss\n",
    "        else:\n",
    "            loss = source_ce_loss\n",
    "        \n",
    "        return loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_out, class_1_source_out, class_0_target_out, class_1_target_out\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ab0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_intra_inter_mmd(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag_phase, GAMMA_inter_class, GAMMA_intra_class):\n",
    "        \n",
    "        #Feature extraction\n",
    "        outputs_cnn, x_fc1 = model_cnn(data.float())\n",
    "        x_fc2, x_fc3 = model_fc(x_fc1)\n",
    "        \n",
    "        batch_size = len(labels_source)         \n",
    "        \n",
    "        #Classification\n",
    "        source_x_flatten = outputs_cnn[:batch_size, :]\n",
    "        target_x_flatten = outputs_cnn[batch_size:, :]\n",
    "        x_src = x_fc1[:batch_size, :]\n",
    "        x_tar = x_fc1[batch_size:, :]\n",
    "        source_out = x_fc2[:batch_size, :]\n",
    "        target_out = x_fc2[batch_size:, :]\n",
    "        source_pred = x_fc3[:batch_size, :]\n",
    "        target_pred = x_fc3[batch_size:, :]\n",
    "        \n",
    "        #CE loss\n",
    "        source_ce_loss = criterion(source_pred, labels_source)\n",
    "        target_ce_loss = criterion(target_pred, labels_target)\n",
    "\n",
    "        #collect information about labels, predictions to calculate accuracy\n",
    "        n_correct_source = 0\n",
    "        n_correct_target = 0\n",
    "        n_samples_source = 0\n",
    "        n_samples_target = 0\n",
    "        \n",
    "        # list of classified latent space features in flattend CNN\n",
    "        class_0_source_x_flatten = source_x_flatten[labels_source==0]\n",
    "        class_1_source_x_flatten = source_x_flatten[labels_source==1]\n",
    "        class_0_target_x_flatten = target_x_flatten[labels_target==0]\n",
    "        class_1_target_x_flatten = target_x_flatten[labels_target==1]\n",
    "        \n",
    "        # list of classified latent space features in FC1\n",
    "        class_0_source_out = source_out[labels_source==0]\n",
    "        class_1_source_out = source_out[labels_source==1]\n",
    "        class_0_target_out = target_out[labels_target==0]\n",
    "        class_1_target_out = target_out[labels_target==1]\n",
    "        \n",
    "        # list of classified latent space features in FC2\n",
    "        class_0_source_x = x_src[labels_source==0]\n",
    "        class_1_source_x = x_src[labels_source==1]\n",
    "        class_0_target_x = x_tar[labels_target==0]\n",
    "        class_1_target_x = x_tar[labels_target==1]\n",
    "        \n",
    "        argmax_source_pred = torch.argmax(source_pred, dim=1)\n",
    "        result_source_pred = argmax_source_pred == labels_source\n",
    "        correct_source_pred = result_source_pred[result_source_pred == True]\n",
    "        acc_total_source = 100 * len(correct_source_pred)/len(labels_source)\n",
    "        \n",
    "        argmax_target_pred = torch.argmax(target_pred, dim=1)\n",
    "        result_target_pred = argmax_target_pred == labels_target\n",
    "        correct_target_pred = result_target_pred[result_target_pred == True]\n",
    "        acc_total_target = 100 * len(correct_target_pred)/len(labels_target)\n",
    "        \n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        \n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_0 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_0_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_1 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_1_target_x_flatten[:min_1_flatten,:])\n",
    "\n",
    "        mmd_x_class_0_0 = MMD_loss.forward(class_0_source_x[:min_0_x,:],class_0_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_1 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_1_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_0 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_0_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_1 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_1_target_out[:min_1_out,:])\n",
    "        \n",
    "        \n",
    "        \n",
    "        mmd_loss_inter_class = mmd_x_class_0_0 + mmd_x_class_1_1 + mmd_out_class_0_0 + mmd_out_class_1_1 + mmd_flatten_class_0_0 + mmd_flatten_class_1_1\n",
    "        #mmd_loss_inter_class = mmd_flatten_class_0_0 + mmd_flatten_class_1_1\n",
    "\n",
    "        #Intraclass MMD loss\n",
    "        \n",
    "        #get number of elements to caclulcate mmd loss\n",
    "        min_0_flatten = min(class_0_source_x_flatten.size()[0], class_1_target_x_flatten.size()[0])\n",
    "        min_1_flatten = min(class_1_source_x_flatten.size()[0], class_0_target_x_flatten.size()[0])\n",
    "        \n",
    "        min_0_x = min(class_0_source_x.size()[0], class_1_target_x.size()[0])\n",
    "        min_1_x = min(class_1_source_x.size()[0], class_0_target_x.size()[0])\n",
    "        \n",
    "        min_0_out = min(class_0_source_out.size()[0], class_1_target_out.size()[0])\n",
    "        min_1_out = min(class_1_source_out.size()[0], class_0_target_out.size()[0])\n",
    "        \n",
    "        mmd_flatten_class_0_1 = MMD_loss.forward(class_0_source_x_flatten[:min_0_flatten,:], class_1_target_x_flatten[:min_0_flatten,:])\n",
    "        mmd_flatten_class_1_0 = MMD_loss.forward(class_1_source_x_flatten[:min_1_flatten,:], class_0_target_x_flatten[:min_1_flatten,:])\n",
    "        \n",
    "        mmd_x_class_0_1= MMD_loss.forward(class_0_source_x[:min_0_x,:], class_1_target_x[:min_0_x,:])\n",
    "        mmd_x_class_1_0 = MMD_loss.forward(class_1_source_x[:min_1_x,:], class_0_target_x[:min_1_x,:])\n",
    "        \n",
    "        mmd_out_class_0_1 = MMD_loss.forward(class_0_source_out[:min_0_out,:], class_1_target_out[:min_0_out,:])\n",
    "        mmd_out_class_1_0 = MMD_loss.forward(class_1_source_out[:min_1_out,:], class_0_target_out[:min_1_out,:])\n",
    "        \n",
    "        mmd_loss_intra_class = mmd_x_class_0_1 + mmd_x_class_1_0 + mmd_out_class_0_1 + mmd_out_class_1_0 + mmd_flatten_class_0_1 + mmd_flatten_class_1_0\n",
    "        #mmd_loss_intra_class = mmd_flatten_class_0_1 + mmd_flatten_class_1_0\n",
    "        \n",
    "        #total mmd loss\n",
    "        mmd_loss = GAMMA_inter_class * mmd_loss_inter_class - GAMMA_intra_class * mmd_loss_intra_class\n",
    "        \n",
    "        if MMD_loss_flag_phase == True:\n",
    "            loss = source_ce_loss + mmd_loss\n",
    "        else:\n",
    "            loss = source_ce_loss\n",
    "        \n",
    "        return loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_out, class_1_source_out, class_0_target_out, class_1_target_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d08b6f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "writer_graph = SummaryWriter('runs/Dataloader2/graph')\n",
    "writer_source_val = SummaryWriter('runs/Dataloader2/source_val')\n",
    "writer_source_mmd = SummaryWriter('runs/Dataloader2/source_mmd')\n",
    "writer_source_ce = SummaryWriter('runs/Dataloader2/source_ce')\n",
    "writer_target_val = SummaryWriter('runs/Dataloader2/target_val')\n",
    "writer_target_mmd = SummaryWriter('runs/Dataloader2/target_mmd')\n",
    "writer_target_ce = SummaryWriter('runs/Dataloader2/target_ce')\n",
    "\n",
    "writer_source = {}\n",
    "writer_source[\"val\"] = writer_source_val\n",
    "writer_source[\"mmd\"] = writer_source_mmd\n",
    "writer_source[\"ce\"] = writer_source_ce\n",
    "\n",
    "writer_target = {}\n",
    "writer_target[\"val\"] = writer_target_val\n",
    "writer_target[\"mmd\"] = writer_target_mmd\n",
    "writer_target[\"ce\"] = writer_target_ce\n",
    "\n",
    "\n",
    "#define training params\n",
    "num_epochs = 10\n",
    "GAMMA_inter_class = 10\n",
    "GAMMA_intra_class = 10\n",
    "SIGMA = torch.tensor([1,2,4,8,16],dtype=torch.float64)\n",
    "\n",
    "#define loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "MMD_loss = MMD_loss(fix_sigma = SIGMA)\n",
    "\n",
    "\n",
    "optimizer1 = torch.optim.Adam([\n",
    "{'params': model_cnn.parameters()},\n",
    "{'params': model_fc.parameters(), 'lr': 1e-4}\n",
    "], lr=1e-2, betas=(0.9, 0.999))\n",
    "\n",
    "optimizer2 = torch.optim.Adam(model_fc.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
    "\n",
    "#training iterations\n",
    "phases = [\"val\", \"mmd\", \"ce\"]\n",
    "\n",
    "#mmd_loss_flag\n",
    "MMD_loss_flag = {}\n",
    "MMD_loss_flag[\"val\"] = True\n",
    "MMD_loss_flag[\"mmd\"] = True\n",
    "MMD_loss_flag[\"ce\"] = False\n",
    "\n",
    "\n",
    "#init train data for each batch\n",
    "loss_collected = 0\n",
    "source_ce_loss_collected = 0\n",
    "target_ce_loss_collected = 0\n",
    "mmd_loss_collected = 0\n",
    "acc_total_source_collected = 0\n",
    "acc_total_target_collected = 0\n",
    "\n",
    "#plot lists\n",
    "mmd_loss_list = {}\n",
    "mmd_loss_list['val']=[]\n",
    "mmd_loss_list['mmd']=[]\n",
    "mmd_loss_list['ce'] = []\n",
    "\n",
    "ce_loss_list_source = {}\n",
    "ce_loss_list_source['val']=[]\n",
    "ce_loss_list_source['mmd']=[]\n",
    "ce_loss_list_source['ce'] = []\n",
    "\n",
    "ce_loss_list_target = {}\n",
    "ce_loss_list_target['val']=[]\n",
    "ce_loss_list_target['mmd']=[]\n",
    "ce_loss_list_target['ce'] = []\n",
    "\n",
    "accuracy_list_source = {}\n",
    "accuracy_list_source['val']=[]\n",
    "accuracy_list_source['mmd']=[]\n",
    "accuracy_list_source['ce'] = []\n",
    "\n",
    "accuracy_list_target = {}\n",
    "accuracy_list_target['val']=[]\n",
    "accuracy_list_target['mmd']=[]\n",
    "accuracy_list_target['ce'] = []\n",
    "\n",
    "# Train and Validate the model\n",
    "for epoch in range(num_epochs):\n",
    "    #plot mmd\n",
    "    class_0_source_out_collect = torch.empty((0,3))\n",
    "    class_1_source_out_collect = torch.empty((0,3))\n",
    "    class_0_target_out_collect = torch.empty((0,3))\n",
    "    class_1_target_out_collect = torch.empty((0,3))\n",
    "\n",
    "    \n",
    "    \n",
    "    for phase in phases:\n",
    "        iter_loader_source = iter(source_loader[phase])\n",
    "        iter_loader_target = iter(target_loader[phase])\n",
    "        for i in range(len(iter_loader_source)):\n",
    "            \n",
    "            ########Forward pass########\n",
    "            data_source, labels_source = iter_loader_source.next() #batch_size number of windows and labels from source domain\n",
    "            data_target, labels_target = iter_loader_target.next() #batch_size number of windows from target domain\n",
    "            data = torch.cat((data_source, data_target), dim=0) #concat the windows to 2*batch_size number of windows\n",
    "            \n",
    "            \n",
    "            if phase == \"val\":\n",
    "                \n",
    "                #no training\n",
    "                model_cnn.train(False)\n",
    "                model_fc.train(False)\n",
    "                \n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    _, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, class_0_source_out, class_1_source_out, class_0_target_out, class_1_target_out = forward_intra_inter_mmd(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                    \n",
    "                    # collect latent features for plot \n",
    "                    class_0_source_out_collect = torch.cat((class_0_source_out_collect, class_0_source_out), 0)\n",
    "                    class_1_source_out_collect = torch.cat((class_1_source_out_collect, class_1_source_out), 0)\n",
    "                    class_0_target_out_collect = torch.cat((class_0_target_out_collect, class_0_target_out), 0)\n",
    "                    class_1_target_out_collect = torch.cat((class_1_target_out_collect, class_1_target_out), 0)\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            elif phase == \"mmd\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward_intra_inter_mmd(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer1.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer1.step()\n",
    "                \n",
    "            elif phase == \"ce\":\n",
    "                \n",
    "                #training\n",
    "                model_cnn.train(True)\n",
    "                model_fc.train(True)\n",
    "                \n",
    "                ########Forward pass########\n",
    "                loss, mmd_loss, source_ce_loss, target_ce_loss, acc_total_source, acc_total_target, _, _, _, _ = forward_intra_inter_mmd(model_cnn, model_fc, data, labels_source, labels_target, criterion, MMD_loss, MMD_loss_flag[phase], GAMMA_inter_class, GAMMA_intra_class)\n",
    "                \n",
    "                mmd_loss = mmd_loss.detach()\n",
    "                source_ce_loss = source_ce_loss.detach()\n",
    "                target_ce_loss = target_ce_loss.detach()\n",
    "                ########Backward pass########\n",
    "                optimizer2.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer2.step()\n",
    "            \n",
    "            # collect train data for each train phase\n",
    "            mmd_loss_collected += mmd_loss\n",
    "            source_ce_loss_collected += source_ce_loss\n",
    "            target_ce_loss_collected += target_ce_loss\n",
    "            acc_total_source_collected += acc_total_source\n",
    "            acc_total_target_collected += acc_total_target\n",
    "            \n",
    "            \n",
    "                \n",
    "        #plot\n",
    "        if phase == \"val\" and (epoch ==0 or epoch ==2 or epoch == 4 or epoch ==6):\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.gcf().set_size_inches((20, 20)) \n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "            m = [1,2,3,4]\n",
    "            data = [class_0_source_out_collect, class_1_source_out_collect, class_0_target_out_collect, class_1_target_out_collect]\n",
    "            for i in range(4):\n",
    "                ax.scatter(data[i][:,0], data[i][:,1], data[i][:,2], marker=m[i])\n",
    "            \n",
    "            plt.show()\n",
    "            fig.savefig(f\"no_mmd_epoch{epoch}\")            \n",
    "\n",
    "        \n",
    "        # Normalize collected train data for each train phase\n",
    "        running_mmd_loss = mmd_loss_collected / len(source_loader[phase])\n",
    "        \n",
    "        running_acc_source = acc_total_source_collected / len(source_loader[phase])\n",
    "        running_acc_target = acc_total_target_collected / len(target_loader[phase])\n",
    "        \n",
    "        running_source_ce_loss = source_ce_loss_collected / len(source_loader[phase])\n",
    "        running_target_ce_loss = target_ce_loss_collected / len(target_loader[phase])\n",
    "        \n",
    "        \n",
    "        #Add train data to plot list\n",
    "        accuracy_list_source[phase].append(running_acc_source)\n",
    "        accuracy_list_target[phase].append(running_acc_target)\n",
    "        \n",
    "        ce_loss_list_source[phase].append(running_source_ce_loss)\n",
    "        ce_loss_list_target[phase].append(running_target_ce_loss)\n",
    "        \n",
    "        mmd_loss_list[phase].append(running_mmd_loss)\n",
    "\n",
    "\n",
    "        #Add train data to tensorflow list\n",
    "        writer_source[phase].add_scalar(f'accuracy', running_acc_source, epoch)\n",
    "        writer_target[phase].add_scalar(f'accuracy', running_acc_target, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'ce_loss', running_source_ce_loss, epoch)\n",
    "        writer_target[phase].add_scalar(f'ce_loss', running_target_ce_loss, epoch)\n",
    "        \n",
    "        writer_source[phase].add_scalar(f'mmd_loss', running_mmd_loss, epoch)\n",
    "        \n",
    "\n",
    "        #reset train data for each batch\n",
    "        loss_collected = 0\n",
    "        source_ce_loss_collected = 0\n",
    "        target_ce_loss_collected = 0\n",
    "        mmd_loss_collected = 0\n",
    "        acc_total_source_collected = 0\n",
    "        acc_total_target_collected = 0\n",
    "            \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} successfull\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0641c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.title('Accuracy Source Domain')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig1.savefig('Accuracy Source Domain')\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.title('Accuracy Target Domain')\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['mmd'], 'mo-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig2.savefig('Accuracy Target Domain')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.title('CE-Loss Source Domain')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig3.savefig('CE_Loss Source Domain')\n",
    "\n",
    "fig4 = plt.figure()\n",
    "plt.title('CE-Loss Target Domain')\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['mmd'], 'mo-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig4.savefig('CE_Loss Target Domain')\n",
    "\n",
    "fig5 = plt.figure()\n",
    "plt.title('MMD-Loss')\n",
    "plt.plot(mmd_loss_list['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig5.savefig('MMD_Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['mmd'], 'ro-', label = 'MMD-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['mmd'], 'mo-', label = 'MMD-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig1.savefig('Accuracy')\n",
    "\n",
    "fig2= plt.figure()\n",
    "plt.title('CE-Loss')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['mmd'], 'ro-', label = 'MMD-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['mmd'], 'mo-', label = 'MMD-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig2.savefig('CE_Loss')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.title('MMD-Loss')\n",
    "plt.plot(mmd_loss_list['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['mmd'], 'ro-', label = 'MMD-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig3.savefig('MMD_Loss')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42336f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#to test\n",
    "fig1 = plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'Source-CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['mmd'], 'ro-', label = 'Source-Target-CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'Source-CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['mmd'], 'mo-', label = 'Source-Target-CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig1.savefig('Accuracy')\n",
    "\n",
    "fig2= plt.figure()\n",
    "plt.title('CE-Loss')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'Source-CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['mmd'], 'ro-', label = 'Source-Target-CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'Source-CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['mmd'], 'mo-', label = 'Source-Target-CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig2.savefig('CE_Loss')\n",
    "\n",
    "#to test\n",
    "fig3 = plt.figure()\n",
    "plt.title('Accuracy-Source')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'Source-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['mmd'], 'ro-', label = 'Source-Target-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig3.savefig('Accuracy-Source')\n",
    "\n",
    "#to test\n",
    "fig4 = plt.figure()\n",
    "plt.title('Accuracy-Target')\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'Source-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['mmd'], 'mo-', label = 'Source-Target-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig4.savefig('Accuracy-Target')\n",
    "\n",
    "fig5= plt.figure()\n",
    "plt.title('CE-Loss Source')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'Source-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['mmd'], 'ro-', label = 'Source-Targegt-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig5.savefig('CE_Loss Source')\n",
    "\n",
    "fig6= plt.figure()\n",
    "plt.title('CE-Loss Target')\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'Source-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['mmd'], 'mo-', label = 'Source-Target-CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig6.savefig('CE_Loss Target')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78cdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to test\n",
    "\"\"\"\n",
    "fig1 = plt.figure()\n",
    "plt.title('Accuracy')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['ce'], 'ro-', label = 'CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig1.savefig('Accuracy')\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.title('Accuracy Source Domain')\n",
    "plt.plot(accuracy_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig2.savefig('Accuracy Source Domain')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.title('Accuracy Target Domain')\n",
    "plt.plot(accuracy_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(accuracy_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig3.savefig('Accuracy Target Domain')\n",
    "\n",
    "\n",
    "fig4= plt.figure()\n",
    "plt.title('CE-Loss')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'CE-Loss-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val-Source', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'CE-Loss-Target', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val-Target', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig4.savefig('CE-Loss')\n",
    "\n",
    "fig5= plt.figure()\n",
    "plt.title('CE-Loss Source Domain')\n",
    "plt.plot(ce_loss_list_source['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_source['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig5.savefig('CE-Loss Source Domain')\n",
    "\n",
    "fig6= plt.figure()\n",
    "plt.title('CE-Loss Target Domain')\n",
    "plt.plot(ce_loss_list_target['ce'], 'co-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(ce_loss_list_target['val'], 'yo-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig6.savefig('CE-Loss Target Domain')\n",
    "\n",
    "fig7 = plt.figure()\n",
    "plt.title('MMD-Loss')\n",
    "plt.plot(mmd_loss_list['ce'], 'bo-', label = 'CE-Loss', linewidth=1,markersize=0.1)\n",
    "plt.plot(mmd_loss_list['val'], 'go-', label = 'Val', linewidth=1,markersize=0.1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "fig7.savefig('MMD-Loss')\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
